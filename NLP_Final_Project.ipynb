{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CwjfnsUoSFTX",
        "PnNdmsUwQCJe"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "643503971d704b0db9b580a509a968b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87f6558165a24d90a906b4e6bc4dbaa1",
              "IPY_MODEL_cb68ca76c2a642afba3cc7e427fe6ca0",
              "IPY_MODEL_66ac7b51dc4843bfbbdfaa688e2a60f0"
            ],
            "layout": "IPY_MODEL_28309f98c86b4caab9d0203c6b9a96f6"
          }
        },
        "87f6558165a24d90a906b4e6bc4dbaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c19dccda3b8148d68f5d12deb0c0375d",
            "placeholder": "​",
            "style": "IPY_MODEL_ccfc6c6ad22a4fba8caeb9f7b6ac1f9f",
            "value": "config.json: 100%"
          }
        },
        "cb68ca76c2a642afba3cc7e427fe6ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d0359ab010845038e934f4993985a45",
            "max": 1604,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dfda9510a7a4fe7bbcd76a46158e2a5",
            "value": 1604
          }
        },
        "66ac7b51dc4843bfbbdfaa688e2a60f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06a7cbd57684330b16668b716b6fcd0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d433bf4afb747938e7e7dfeb7850a0f",
            "value": " 1.60k/1.60k [00:00&lt;00:00, 28.1kB/s]"
          }
        },
        "28309f98c86b4caab9d0203c6b9a96f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19dccda3b8148d68f5d12deb0c0375d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccfc6c6ad22a4fba8caeb9f7b6ac1f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d0359ab010845038e934f4993985a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dfda9510a7a4fe7bbcd76a46158e2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f06a7cbd57684330b16668b716b6fcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d433bf4afb747938e7e7dfeb7850a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b90501a43b54a6ea4d85911e38ef0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6006ec1183842528fcb3014599df5f1",
              "IPY_MODEL_7943453d0d8f4032810247d1b3013fd4",
              "IPY_MODEL_d8b4439fed02436f93f2a2fbc790219e"
            ],
            "layout": "IPY_MODEL_37d2d29e35aa49c2af8f1d2d75eddcf9"
          }
        },
        "c6006ec1183842528fcb3014599df5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79d4d8e500f41aab7c5f51601a45d0d",
            "placeholder": "​",
            "style": "IPY_MODEL_6bedd7277d0b4c049638cfa26456c492",
            "value": "configuration_openelm.py: 100%"
          }
        },
        "7943453d0d8f4032810247d1b3013fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_909cffca424e45abb3b111aac582b651",
            "max": 14264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1882bc86806f46ee932ba4aa41101415",
            "value": 14264
          }
        },
        "d8b4439fed02436f93f2a2fbc790219e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b164d91a19f74a0e9f9b04c9ade9a88e",
            "placeholder": "​",
            "style": "IPY_MODEL_4cbbe58a532445739bf4c4e4fefd186d",
            "value": " 14.3k/14.3k [00:00&lt;00:00, 150kB/s]"
          }
        },
        "37d2d29e35aa49c2af8f1d2d75eddcf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79d4d8e500f41aab7c5f51601a45d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bedd7277d0b4c049638cfa26456c492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909cffca424e45abb3b111aac582b651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1882bc86806f46ee932ba4aa41101415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b164d91a19f74a0e9f9b04c9ade9a88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbbe58a532445739bf4c4e4fefd186d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65e47115ad0a4433a6e3250e9f80c772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b69182ddc2d4ee0aa074866b7a46ddd",
              "IPY_MODEL_27591b16b92a4d7ebb58bccbfb34508a",
              "IPY_MODEL_8b1c233892ac4e93be9d1d8399690ab4"
            ],
            "layout": "IPY_MODEL_7d8a825d8f114b8a98e2522f5fc5c9b8"
          }
        },
        "6b69182ddc2d4ee0aa074866b7a46ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f813b3f612a42cc98b62fc473fdf18a",
            "placeholder": "​",
            "style": "IPY_MODEL_43eeadd664154cdfa0ffcd869f0203fe",
            "value": "modeling_openelm.py: 100%"
          }
        },
        "27591b16b92a4d7ebb58bccbfb34508a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb515221d5ad400188e4f629167a5f7c",
            "max": 39348,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08d05b0fc6ac4960bf178cbeafd1a38a",
            "value": 39348
          }
        },
        "8b1c233892ac4e93be9d1d8399690ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045fb37f711942229d6775058b6784cc",
            "placeholder": "​",
            "style": "IPY_MODEL_d30710276575444884e927fe00d08951",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 934kB/s]"
          }
        },
        "7d8a825d8f114b8a98e2522f5fc5c9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f813b3f612a42cc98b62fc473fdf18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43eeadd664154cdfa0ffcd869f0203fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb515221d5ad400188e4f629167a5f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d05b0fc6ac4960bf178cbeafd1a38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "045fb37f711942229d6775058b6784cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d30710276575444884e927fe00d08951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8a465665fb446068c0653b0e63a3ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33e5043d6286490684c4bb5373cdd4a0",
              "IPY_MODEL_5512f4454e6b4bb2a493bab2a4b4ddc1",
              "IPY_MODEL_e4bc2d642ed046ac8a24d42fddd9fdb7"
            ],
            "layout": "IPY_MODEL_531a1840c331470bae9b0d98b77a9b57"
          }
        },
        "33e5043d6286490684c4bb5373cdd4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0568742e7d549e796c4f1c05e26af6f",
            "placeholder": "​",
            "style": "IPY_MODEL_7608b4126e474ce590cc852f099824e2",
            "value": "model.safetensors: 100%"
          }
        },
        "5512f4454e6b4bb2a493bab2a4b4ddc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ca55b223b8142f9808886189fa0669d",
            "max": 2159808696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ccf4b1811ce47db93538f6d8a6a289b",
            "value": 2159808696
          }
        },
        "e4bc2d642ed046ac8a24d42fddd9fdb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757f278de94e4d54878b3f24058b2513",
            "placeholder": "​",
            "style": "IPY_MODEL_e616cddccd0d4cf4a84ec823f21184da",
            "value": " 2.16G/2.16G [00:30&lt;00:00, 102MB/s]"
          }
        },
        "531a1840c331470bae9b0d98b77a9b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0568742e7d549e796c4f1c05e26af6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7608b4126e474ce590cc852f099824e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ca55b223b8142f9808886189fa0669d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccf4b1811ce47db93538f6d8a6a289b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "757f278de94e4d54878b3f24058b2513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e616cddccd0d4cf4a84ec823f21184da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3832ffca59b447eaa0d0666e7e34a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec116d77c8f74520b8177d2b0e0341a7",
              "IPY_MODEL_f911199098a44e2a9afc53baf27e6dd8",
              "IPY_MODEL_9aba34c9cf3d4d6ba0fee6757889c095"
            ],
            "layout": "IPY_MODEL_a8877aaf30034b5ab8da3dfa8d5fb8c7"
          }
        },
        "ec116d77c8f74520b8177d2b0e0341a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d37450902dc4051a5a366fa6f1cab19",
            "placeholder": "​",
            "style": "IPY_MODEL_480b9d9db7354f3384ba8170b1eb4891",
            "value": "generation_config.json: 100%"
          }
        },
        "f911199098a44e2a9afc53baf27e6dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478b247c4fc643c1b23456bd02ef01e6",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_976f6c92905c45438939420cbde60d67",
            "value": 111
          }
        },
        "9aba34c9cf3d4d6ba0fee6757889c095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bde640f202e2470ba57645020dc74239",
            "placeholder": "​",
            "style": "IPY_MODEL_cde5f3ba4e7e4bbf9f6cdb74132176f8",
            "value": " 111/111 [00:00&lt;00:00, 4.98kB/s]"
          }
        },
        "a8877aaf30034b5ab8da3dfa8d5fb8c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d37450902dc4051a5a366fa6f1cab19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480b9d9db7354f3384ba8170b1eb4891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "478b247c4fc643c1b23456bd02ef01e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "976f6c92905c45438939420cbde60d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bde640f202e2470ba57645020dc74239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde5f3ba4e7e4bbf9f6cdb74132176f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e5d7e25559e47ccb91b23e48cb31f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9ae0a575fa0470fa19ad30c9b58d4ec",
              "IPY_MODEL_e074cffc364349feb7a3122cf1c78a81",
              "IPY_MODEL_fdfae719b1444864a0c2edb2ad79108d"
            ],
            "layout": "IPY_MODEL_559e298311d74f5481fcb9b55600daa9"
          }
        },
        "f9ae0a575fa0470fa19ad30c9b58d4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f1e8d533164e53946dcb81e91da9a7",
            "placeholder": "​",
            "style": "IPY_MODEL_d03af09e7a7b4a69b1dbda31036eee5c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e074cffc364349feb7a3122cf1c78a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae28e39c163e4516ae6e165ceb22185c",
            "max": 776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a76eefca0a204cecbc0407d5bcd6f49b",
            "value": 776
          }
        },
        "fdfae719b1444864a0c2edb2ad79108d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fe0d52b4e0a4d289e8221a925fcddb8",
            "placeholder": "​",
            "style": "IPY_MODEL_7251f1e11c92413293235795d18289c9",
            "value": " 776/776 [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "559e298311d74f5481fcb9b55600daa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f1e8d533164e53946dcb81e91da9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03af09e7a7b4a69b1dbda31036eee5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae28e39c163e4516ae6e165ceb22185c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a76eefca0a204cecbc0407d5bcd6f49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fe0d52b4e0a4d289e8221a925fcddb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7251f1e11c92413293235795d18289c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc3dd2a5648a49efa6220d5017a9e09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37c90765522a4aecb08ddf46e44024dc",
              "IPY_MODEL_0e2d082cbc374064887c516f0d64fcb9",
              "IPY_MODEL_fc44b40efc37473eabbc1d49044eab50"
            ],
            "layout": "IPY_MODEL_290c3ffae5e24244a6efeb45ff14b097"
          }
        },
        "37c90765522a4aecb08ddf46e44024dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a73eb4155e34f2db6be2b38c4755186",
            "placeholder": "​",
            "style": "IPY_MODEL_61c1ca77491c48d5b76f293d29d5157f",
            "value": "tokenizer.model: 100%"
          }
        },
        "0e2d082cbc374064887c516f0d64fcb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_451bf742169e4181b90b156a140e435d",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f97ec2a2ff44a41a4722d25a1b3bf95",
            "value": 499723
          }
        },
        "fc44b40efc37473eabbc1d49044eab50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c438d2d36ab94fe2a5c6ca9f217bad32",
            "placeholder": "​",
            "style": "IPY_MODEL_2413af89bdf64f09a1c158378e9241d2",
            "value": " 500k/500k [00:00&lt;00:00, 843kB/s]"
          }
        },
        "290c3ffae5e24244a6efeb45ff14b097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a73eb4155e34f2db6be2b38c4755186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c1ca77491c48d5b76f293d29d5157f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "451bf742169e4181b90b156a140e435d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f97ec2a2ff44a41a4722d25a1b3bf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c438d2d36ab94fe2a5c6ca9f217bad32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2413af89bdf64f09a1c158378e9241d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2081f5ee6384408db867717bb01a5f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de4d8f321a7b4ce4a46e120042edc27f",
              "IPY_MODEL_960be3842ecf4ae5b9b9aef34a8e8f13",
              "IPY_MODEL_8a29a2898d114017937c957120cc3e28"
            ],
            "layout": "IPY_MODEL_666f80beae21455dad48a25ef59e5879"
          }
        },
        "de4d8f321a7b4ce4a46e120042edc27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347103a3c48642feb8f44ead4d28b137",
            "placeholder": "​",
            "style": "IPY_MODEL_9856c9a85257461ba154ee4f64ac663d",
            "value": "tokenizer.json: 100%"
          }
        },
        "960be3842ecf4ae5b9b9aef34a8e8f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_084b4321a5f54b5fbebdde189c0182d0",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6544eba09e4435b801773f9628d99b8",
            "value": 1842767
          }
        },
        "8a29a2898d114017937c957120cc3e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9ac081297e46ab8582a5fb9df59d7c",
            "placeholder": "​",
            "style": "IPY_MODEL_bcfa85cad4664b239daa83a6f96022a5",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 17.5MB/s]"
          }
        },
        "666f80beae21455dad48a25ef59e5879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347103a3c48642feb8f44ead4d28b137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9856c9a85257461ba154ee4f64ac663d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "084b4321a5f54b5fbebdde189c0182d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6544eba09e4435b801773f9628d99b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d9ac081297e46ab8582a5fb9df59d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcfa85cad4664b239daa83a6f96022a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0ee309202604c31a3cd84db1e51f0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bad1866b922843c1a59b574c6979e5f4",
              "IPY_MODEL_e021e47f1ceb45fead26fd3d3cea27f2",
              "IPY_MODEL_db621fa05b444c1b94ba7386fdea36e0"
            ],
            "layout": "IPY_MODEL_669a286f7585452082155896c9636b00"
          }
        },
        "bad1866b922843c1a59b574c6979e5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06435f0ce2741bd8ac00fc9543c293c",
            "placeholder": "​",
            "style": "IPY_MODEL_df019ab0390f4a0d812a63ee01bf8bd6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e021e47f1ceb45fead26fd3d3cea27f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43346ccc3f946288e54d86ecb08e7f1",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0c55765141643f79f8a35618512df6e",
            "value": 414
          }
        },
        "db621fa05b444c1b94ba7386fdea36e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e453a0a97deb48d09b552cb17d28d10e",
            "placeholder": "​",
            "style": "IPY_MODEL_cca5947e690a43d1b6267c261c235ffa",
            "value": " 414/414 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "669a286f7585452082155896c9636b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06435f0ce2741bd8ac00fc9543c293c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df019ab0390f4a0d812a63ee01bf8bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43346ccc3f946288e54d86ecb08e7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c55765141643f79f8a35618512df6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e453a0a97deb48d09b552cb17d28d10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca5947e690a43d1b6267c261c235ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project of the NLP 2024 Course\n",
        "\n",
        "Slides: https://docs.google.com/presentation/d/1NbH4E2HKVHQlaW_ivKCyjpWuEJFvmz3bSKsX8fs67tA/edit#slide=id.g2d17364e0e4_0_34\n"
      ],
      "metadata": {
        "id": "A_e9oz5Z_pLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "Get your own huggingface access token via\n",
        "https://huggingface.co/settings/tokens\n",
        "\n",
        "And set up HF_TOKEN as a secret of Colab"
      ],
      "metadata": {
        "id": "ntG5sC-XvQk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "OFoUUaYH6tZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b2ac03-d283-4004-f5dc-8430816a8400"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Test Dataset with Gemini\n",
        "Use the data on arxiv : https://paperswithcode.com/dataset/arxiv-10"
      ],
      "metadata": {
        "id": "CwjfnsUoSFTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from time import sleep\n",
        "\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "LW_jYUceSJxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### User Gemini\n",
        "GEMINI_API_KEY = \"your_api_key\" # Please change your api key here!\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "6XVIlaiOSehr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('output_new.csv', 'w', newline='') as f1:\n",
        "  writer = csv.writer(f1)\n",
        "  writer.writerow(['Abstract', 'Metholodgy_LLM'])"
      ],
      "metadata": {
        "id": "MMUXj0nVSj59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"arxiv100.csv\")\n",
        "data = data.sample(frac=1, random_state=0)\n",
        "\n",
        "abstract_example = \"\"\"\n",
        "The reliability of self-labeled data is an important issue when the data are regarded as ground-truth for training and testing learning-based models.\n",
        "This paper addresses the issue of false-alarm hashtags in the self-labeled data for irony detection.\n",
        "We analyze the ambiguity of hashtag usages and propose a novel neural network-based model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection.\n",
        "Furthermore, we apply our model to prune the self-labeled training data.\n",
        "Experimental results show that the irony detection model trained on the less but cleaner training instances outperforms the models trained on all data.\n",
        "\"\"\"\n",
        "\n",
        "method_example = \"\"\"\n",
        "We analyze the ambiguity of hashtag usages and propose a novel neural network-based model,\n",
        "which incorporates linguistic information from different aspects,\n",
        "to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection. Furthermore,\n",
        "we apply our model to prune the self-labeled training data.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4D-1bnQvSq__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num=0\n",
        "for i in range(num, 100):\n",
        "  print(\"Question\", num)\n",
        "  abstract = data['abstract'][i]\n",
        "  prompt = f\"\"\"\n",
        "  I would like you to extract the methodology from the abstract.\n",
        "  Below is an example for your reference:\n",
        "  \\n\\n\\n\n",
        "  Abstract Example: {abstract_example}\n",
        "  \\n\\n\\n\n",
        "  Metholodhy Example: {method_example}\n",
        "  \\n\\n\\n\n",
        "  Now, Here is an abstract of an article:\n",
        "  Abstract: {abstract}\n",
        "  \\n\\n\\n\n",
        "  Please extract the methodology from the abstract and don't use markdown.\n",
        "  You just need to extract the sentences related to the method like the example above, no need to change their meaning.\n",
        "  \"\"\"\n",
        "\n",
        "  response = model.generate_content(prompt)\n",
        "  sleep(30)\n",
        "\n",
        "  prompt_round2 = f\"\"\"\"\n",
        "  Based on the following summary's methodology, please rephrase it and don't use markdown or list. \\n\\n\\n\n",
        "  Summary:\n",
        "  {response.text}\n",
        "  \"\"\"\n",
        "\n",
        "  response_final = model.generate_content(prompt_round2)\n",
        "\n",
        "  with open('output_new.csv', 'a+', newline='') as f2:\n",
        "      writer = csv.writer(f2)\n",
        "      writer.writerow([data['abstract'][i], response_final.text])\n",
        "      f2.flush()\n",
        "\n",
        "  num+=1\n",
        "  sleep(30)"
      ],
      "metadata": {
        "id": "Pzg5iRM9Swfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the pre-trained model"
      ],
      "metadata": {
        "id": "R5t5Dtt-6EDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Module to generate OpenELM output given a model and an input prompt.\"\"\"\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "import argparse\n",
        "from typing import Optional, Union\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BertForQuestionAnswering, BertTokenizer\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# The following function is revised from https://huggingface.co/apple/OpenELM/blob/main/generate_openelm.py\n",
        "def generate(\n",
        "    prompt: str,\n",
        "    model: Union[str, AutoModelForCausalLM],\n",
        "    hf_access_token: str = None,\n",
        "    tokenizer: Union[str, AutoTokenizer] = 'meta-llama/Llama-2-7b-hf',\n",
        "    device: Optional[str] = None,\n",
        "    max_length: int = 1024,\n",
        "    assistant_model: Optional[Union[str, AutoModelForCausalLM]] = None,\n",
        "    generate_kwargs: Optional[dict] = None,\n",
        ") -> str:\n",
        "    \"\"\" Generates output given a prompt.\n",
        "    Args:\n",
        "        prompt: The string prompt.\n",
        "        model: The LLM Model. If a string is passed, it should be the path to\n",
        "            the hf converted checkpoint.\n",
        "        hf_access_token: Hugging face access token.\n",
        "        tokenizer: Tokenizer instance. If model is set as a string path,\n",
        "            the tokenizer will be loaded from the checkpoint.\n",
        "        device: String representation of device to run the model on. If None\n",
        "            and cuda available it would be set to cuda:0 else cpu.\n",
        "        max_length: Maximum length of tokens, input prompt + generated tokens.\n",
        "        assistant_model: If set, this model will be used for\n",
        "            speculative generation. If a string is passed, it should be the\n",
        "            path to the hf converted checkpoint.\n",
        "        generate_kwargs: Extra kwargs passed to the hf generate function.\n",
        "    Returns:\n",
        "        output_text: output generated as a string.\n",
        "        generation_time: generation time in seconds.\n",
        "    Raises:\n",
        "        ValueError: If device is set to CUDA but no CUDA device is detected.\n",
        "        ValueError: If tokenizer is not set.\n",
        "        ValueError: If hf_access_token is not specified.\n",
        "    \"\"\"\n",
        "    if not device:\n",
        "        if torch.cuda.is_available() and torch.cuda.device_count():\n",
        "            device = \"cuda:0\"\n",
        "            logging.warning(\n",
        "                'inference device is not set, using cuda:0, %s',\n",
        "                torch.cuda.get_device_name(0)\n",
        "            )\n",
        "        else:\n",
        "            device = 'cpu'\n",
        "            logging.warning(\n",
        "                (\n",
        "                    'No CUDA device detected, using cpu, '\n",
        "                    'expect slower speeds.'\n",
        "                )\n",
        "            )\n",
        "\n",
        "    if 'cuda' in device and not torch.cuda.is_available():\n",
        "        raise ValueError('CUDA device requested but no CUDA device detected.')\n",
        "\n",
        "    if not tokenizer:\n",
        "        raise ValueError('Tokenizer is not set in the generate function.')\n",
        "\n",
        "    if not hf_access_token:\n",
        "        raise ValueError((\n",
        "            'Hugging face access token needs to be specified. '\n",
        "            'Please refer to https://huggingface.co/docs/hub/security-tokens'\n",
        "            ' to obtain one.'\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if isinstance(model, str):\n",
        "        checkpoint_path = model\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            checkpoint_path,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "    model.to(device).eval()\n",
        "    if isinstance(tokenizer, str):\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            tokenizer,\n",
        "            token=hf_access_token,\n",
        "        )\n",
        "\n",
        "    # Speculative mode\n",
        "    draft_model = None\n",
        "    if assistant_model:\n",
        "        draft_model = assistant_model\n",
        "        if isinstance(assistant_model, str):\n",
        "            draft_model = AutoModelForCausalLM.from_pretrained(\n",
        "                assistant_model,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "        draft_model.to(device).eval()\n",
        "\n",
        "    # Prepare the prompt\n",
        "    tokenized_prompt = tokenizer(prompt)\n",
        "    tokenized_prompt = torch.tensor(\n",
        "        tokenized_prompt['input_ids'],\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    tokenized_prompt = tokenized_prompt.unsqueeze(0)\n",
        "\n",
        "\n",
        "    # Generate\n",
        "    stime = time.time()\n",
        "    output_ids = model.generate(\n",
        "        tokenized_prompt,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=0,\n",
        "        assistant_model=draft_model,\n",
        "        **(generate_kwargs if generate_kwargs else {}),\n",
        "    )\n",
        "    generation_time = time.time() - stime\n",
        "\n",
        "    output_text = tokenizer.decode(\n",
        "        output_ids[0][tokenized_prompt.shape[1]:].tolist(),\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    return output_text, generation_time"
      ],
      "metadata": {
        "id": "gfQmSvzWblXM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement your main function here\n",
        "The input `abstract` is a `str` that forms an abstract of a research paper.\n",
        "Your function will be invoked for returning the **sentence(s)** from the `abstract` that show the **research methodology**."
      ],
      "metadata": {
        "id": "C2upj5yE6I-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentence(abstract: str) -> str:\n",
        "    # # 0.4044943820224719\n",
        "    # prompt = \"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` \\n Don't predict line breaks and other information\" % abstract\n",
        "\n",
        "    # # 0.4122137404580153\n",
        "    # prompt = \"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` \\n Don't predict line breaks and other information\" % abstract\n",
        "\n",
        "    # # 0.5668449197860963\n",
        "    # prompt = \"From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```%s``` \\nDon't predict line breaks and other information\" % abstract\n",
        "\n",
        "    promptList = [\"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` Don't predict line breaks\" % abstract,\n",
        "            \"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` \\n Don't predict line breaks\" % abstract,\n",
        "            \"From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```%s``` \\nDon't predict line breaks and other information\" % abstract]\n",
        "\n",
        "\n",
        "    output_textList = []\n",
        "\n",
        "    for index, prompt in enumerate(promptList):\n",
        "      print(f\"==============={index}====================\")\n",
        "      print(prompt)\n",
        "      output_text, genertaion_time = generate(\n",
        "          prompt=prompt,\n",
        "          # model=\"apple/OpenELM-450M-Instruct\",\n",
        "          model=\"apple/OpenELM-1_1B-Instruct\",\n",
        "          hf_access_token=userdata.get('HF_TOKEN')\n",
        "      )\n",
        "      output_textList.append(output_text)\n",
        "      print(\"================finish=================\")\n",
        "\n",
        "    return output_textList"
      ],
      "metadata": {
        "id": "_PEde7UC6KSL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your function is expected to be used as follows."
      ],
      "metadata": {
        "id": "0Y6hx64u59Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abstract = \"\"\"The reliability of self-labeled data is an important issue when the data are regarded as ground-truth for training and testing learning-based models.\n",
        "This paper addresses the issue of false-alarm hashtags in the self-labeled data for irony detection.\n",
        "We analyze the ambiguity of hashtag usages and propose a novel neural network-based model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection.\n",
        "Furthermore, we apply our model to prune the self-labeled training data.\n",
        "Experimental results show that the irony detection model trained on the less but cleaner training instances outperforms the models trained on all data.\"\"\"\n",
        "\n",
        "predicted_list = extract_sentence(abstract)\n",
        "print(predicted_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950,
          "referenced_widgets": [
            "643503971d704b0db9b580a509a968b8",
            "87f6558165a24d90a906b4e6bc4dbaa1",
            "cb68ca76c2a642afba3cc7e427fe6ca0",
            "66ac7b51dc4843bfbbdfaa688e2a60f0",
            "28309f98c86b4caab9d0203c6b9a96f6",
            "c19dccda3b8148d68f5d12deb0c0375d",
            "ccfc6c6ad22a4fba8caeb9f7b6ac1f9f",
            "3d0359ab010845038e934f4993985a45",
            "8dfda9510a7a4fe7bbcd76a46158e2a5",
            "f06a7cbd57684330b16668b716b6fcd0",
            "3d433bf4afb747938e7e7dfeb7850a0f",
            "2b90501a43b54a6ea4d85911e38ef0f8",
            "c6006ec1183842528fcb3014599df5f1",
            "7943453d0d8f4032810247d1b3013fd4",
            "d8b4439fed02436f93f2a2fbc790219e",
            "37d2d29e35aa49c2af8f1d2d75eddcf9",
            "d79d4d8e500f41aab7c5f51601a45d0d",
            "6bedd7277d0b4c049638cfa26456c492",
            "909cffca424e45abb3b111aac582b651",
            "1882bc86806f46ee932ba4aa41101415",
            "b164d91a19f74a0e9f9b04c9ade9a88e",
            "4cbbe58a532445739bf4c4e4fefd186d",
            "65e47115ad0a4433a6e3250e9f80c772",
            "6b69182ddc2d4ee0aa074866b7a46ddd",
            "27591b16b92a4d7ebb58bccbfb34508a",
            "8b1c233892ac4e93be9d1d8399690ab4",
            "7d8a825d8f114b8a98e2522f5fc5c9b8",
            "1f813b3f612a42cc98b62fc473fdf18a",
            "43eeadd664154cdfa0ffcd869f0203fe",
            "eb515221d5ad400188e4f629167a5f7c",
            "08d05b0fc6ac4960bf178cbeafd1a38a",
            "045fb37f711942229d6775058b6784cc",
            "d30710276575444884e927fe00d08951",
            "e8a465665fb446068c0653b0e63a3ec1",
            "33e5043d6286490684c4bb5373cdd4a0",
            "5512f4454e6b4bb2a493bab2a4b4ddc1",
            "e4bc2d642ed046ac8a24d42fddd9fdb7",
            "531a1840c331470bae9b0d98b77a9b57",
            "d0568742e7d549e796c4f1c05e26af6f",
            "7608b4126e474ce590cc852f099824e2",
            "1ca55b223b8142f9808886189fa0669d",
            "1ccf4b1811ce47db93538f6d8a6a289b",
            "757f278de94e4d54878b3f24058b2513",
            "e616cddccd0d4cf4a84ec823f21184da",
            "c3832ffca59b447eaa0d0666e7e34a60",
            "ec116d77c8f74520b8177d2b0e0341a7",
            "f911199098a44e2a9afc53baf27e6dd8",
            "9aba34c9cf3d4d6ba0fee6757889c095",
            "a8877aaf30034b5ab8da3dfa8d5fb8c7",
            "2d37450902dc4051a5a366fa6f1cab19",
            "480b9d9db7354f3384ba8170b1eb4891",
            "478b247c4fc643c1b23456bd02ef01e6",
            "976f6c92905c45438939420cbde60d67",
            "bde640f202e2470ba57645020dc74239",
            "cde5f3ba4e7e4bbf9f6cdb74132176f8",
            "5e5d7e25559e47ccb91b23e48cb31f02",
            "f9ae0a575fa0470fa19ad30c9b58d4ec",
            "e074cffc364349feb7a3122cf1c78a81",
            "fdfae719b1444864a0c2edb2ad79108d",
            "559e298311d74f5481fcb9b55600daa9",
            "c9f1e8d533164e53946dcb81e91da9a7",
            "d03af09e7a7b4a69b1dbda31036eee5c",
            "ae28e39c163e4516ae6e165ceb22185c",
            "a76eefca0a204cecbc0407d5bcd6f49b",
            "6fe0d52b4e0a4d289e8221a925fcddb8",
            "7251f1e11c92413293235795d18289c9",
            "fc3dd2a5648a49efa6220d5017a9e09e",
            "37c90765522a4aecb08ddf46e44024dc",
            "0e2d082cbc374064887c516f0d64fcb9",
            "fc44b40efc37473eabbc1d49044eab50",
            "290c3ffae5e24244a6efeb45ff14b097",
            "3a73eb4155e34f2db6be2b38c4755186",
            "61c1ca77491c48d5b76f293d29d5157f",
            "451bf742169e4181b90b156a140e435d",
            "6f97ec2a2ff44a41a4722d25a1b3bf95",
            "c438d2d36ab94fe2a5c6ca9f217bad32",
            "2413af89bdf64f09a1c158378e9241d2",
            "2081f5ee6384408db867717bb01a5f18",
            "de4d8f321a7b4ce4a46e120042edc27f",
            "960be3842ecf4ae5b9b9aef34a8e8f13",
            "8a29a2898d114017937c957120cc3e28",
            "666f80beae21455dad48a25ef59e5879",
            "347103a3c48642feb8f44ead4d28b137",
            "9856c9a85257461ba154ee4f64ac663d",
            "084b4321a5f54b5fbebdde189c0182d0",
            "b6544eba09e4435b801773f9628d99b8",
            "8d9ac081297e46ab8582a5fb9df59d7c",
            "bcfa85cad4664b239daa83a6f96022a5",
            "c0ee309202604c31a3cd84db1e51f0de",
            "bad1866b922843c1a59b574c6979e5f4",
            "e021e47f1ceb45fead26fd3d3cea27f2",
            "db621fa05b444c1b94ba7386fdea36e0",
            "669a286f7585452082155896c9636b00",
            "a06435f0ce2741bd8ac00fc9543c293c",
            "df019ab0390f4a0d812a63ee01bf8bd6",
            "b43346ccc3f946288e54d86ecb08e7f1",
            "e0c55765141643f79f8a35618512df6e",
            "e453a0a97deb48d09b552cb17d28d10e",
            "cca5947e690a43d1b6267c261c235ffa"
          ]
        },
        "id": "TcjRijoPvJWN",
        "outputId": "f900790a-92b6-4598-fb9e-7cc546b92ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============0====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```The reliability of self-labeled data is an important issue when the data are regarded as ground-truth for training and testing learning-based models.\n",
            "This paper addresses the issue of false-alarm hashtags in the self-labeled data for irony detection.\n",
            "We analyze the ambiguity of hashtag usages and propose a novel neural network-based model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection.\n",
            "Furthermore, we apply our model to prune the self-labeled training data.\n",
            "Experimental results show that the irony detection model trained on the less but cleaner training instances outperforms the models trained on all data.``` Don't predict line breaks\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "643503971d704b0db9b580a509a968b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b90501a43b54a6ea4d85911e38ef0f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_openelm.py:   0%|          | 0.00/14.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-1_1B-Instruct:\n",
            "- configuration_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65e47115ad0a4433a6e3250e9f80c772",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_openelm.py:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-1_1B-Instruct:\n",
            "- modeling_openelm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8a465665fb446068c0653b0e63a3ec1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.16G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3832ffca59b447eaa0d0666e7e34a60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e5d7e25559e47ccb91b23e48cb31f02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc3dd2a5648a49efa6220d5017a9e09e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2081f5ee6384408db867717bb01a5f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0ee309202604c31a3cd84db1e51f0de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================finish=================\n",
            "===============1====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```The reliability of self-labeled data is an important issue when the data are regarded as ground-truth for training and testing learning-based models.\n",
            "This paper addresses the issue of false-alarm hashtags in the self-labeled data for irony detection.\n",
            "We analyze the ambiguity of hashtag usages and propose a novel neural network-based model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection.\n",
            "Furthermore, we apply our model to prune the self-labeled training data.\n",
            "Experimental results show that the irony detection model trained on the less but cleaner training instances outperforms the models trained on all data.``` \n",
            " Don't predict line breaks\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:No CUDA device detected, using cpu, expect slower speeds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============2====================\n",
            "From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```The reliability of self-labeled data is an important issue when the data are regarded as ground-truth for training and testing learning-based models.\n",
            "This paper addresses the issue of false-alarm hashtags in the self-labeled data for irony detection.\n",
            "We analyze the ambiguity of hashtag usages and propose a novel neural network-based model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection.\n",
            "Furthermore, we apply our model to prune the self-labeled training data.\n",
            "Experimental results show that the irony detection model trained on the less but cleaner training instances outperforms the models trained on all data.``` \n",
            "Don't predict line breaks and other information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "We will evaluate your module with a close testset.\n",
        "The sentence returned by your function will be compared with a golden reference.\n",
        "The evaluation metric is `ROUGE-L`, which measures the overlap ratio between a predicted output and a reference. The details will be introduced in class."
      ],
      "metadata": {
        "id": "-DorKYCw7U00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "gTJy_hdm5GpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de1358b-9a0b-4077-eb46-71235364dc5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=2f5023bdfa99ee2a702f508dbfdaa8421188c2a9e92262af675fb502ad2ab799\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'])"
      ],
      "metadata": {
        "id": "frSkyu5u5SC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference = \"\"\"We analyze the ambiguity of hashtag usages and propose a novel neural network-based model, which incorporates linguistic information from different aspects, to disambiguate the usage of three hashtags that are widely used to collect the training data for irony detection. Furthermore, we apply our model to prune the self-labeled training data.\"\"\""
      ],
      "metadata": {
        "id": "j05JtmNp-jx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def longest_common_subsequence_words(X, Y):\n",
        "    X_words = X.split()\n",
        "    Y_words = Y.split()\n",
        "    m = len(X_words)\n",
        "    n = len(Y_words)\n",
        "    L = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if X_words[i - 1] == Y_words[j - 1]:\n",
        "                L[i][j] = L[i - 1][j - 1] + 1\n",
        "            else:\n",
        "                L[i][j] = max(L[i - 1][j], L[i][j - 1])\n",
        "\n",
        "    lcs_index = L[m][n]\n",
        "    lcs = [\"\"] * lcs_index\n",
        "    i, j = m, n\n",
        "    while i > 0 and j > 0:\n",
        "        if X_words[i - 1] == Y_words[j - 1]:\n",
        "            lcs[lcs_index - 1] = X_words[i - 1]\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "            lcs_index -= 1\n",
        "        elif L[i - 1][j] > L[i][j - 1]:\n",
        "            i -= 1\n",
        "        else:\n",
        "            j -= 1\n",
        "\n",
        "    return lcs\n",
        "\n",
        "def build_reference_array(reference, predicted):\n",
        "\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    reference = reference.translate(translator)\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    predicted = predicted.translate(translator)\n",
        "\n",
        "    lcs_words = longest_common_subsequence_words(reference, predicted)\n",
        "    reference_words = reference.split()\n",
        "    matched_indices = [0] * len(reference_words)\n",
        "\n",
        "    lcs_word_iter = iter(lcs_words)\n",
        "    current_lcs_word = next(lcs_word_iter, None)\n",
        "\n",
        "    for idx, word in enumerate(reference_words):\n",
        "        if word == current_lcs_word:\n",
        "            matched_indices[idx] = 1\n",
        "            current_lcs_word = next(lcs_word_iter, None)\n",
        "\n",
        "    return matched_indices\n",
        "\n",
        "def segment_and_filter(reference, matched_indices):\n",
        "    reference_words = reference.split()\n",
        "    segments = reference.split('.')\n",
        "    segment_indices = [0]  # 段落開始的索引列表\n",
        "    start_idx = 0\n",
        "\n",
        "    # 計算每個段落開始的單詞索引\n",
        "    for segment in segments:\n",
        "        num_words = len(segment.split())\n",
        "        start_idx += num_words\n",
        "        segment_indices.append(start_idx)\n",
        "\n",
        "    # 確定哪些段落應該被保留\n",
        "    kept_segments = []\n",
        "    for i in range(len(segment_indices) - 1):\n",
        "        start = segment_indices[i]\n",
        "        end = segment_indices[i + 1]\n",
        "        if any(matched_indices[start:end]):\n",
        "            kept_segments.append(segments[i].strip())\n",
        "\n",
        "    return kept_segments\n",
        "\n",
        "def segment_and_filter_with_average(reference, matched_indices):\n",
        "    reference_words = reference.split()\n",
        "    segments = reference.split('.')\n",
        "    segment_indices = [0]\n",
        "    start_idx = 0\n",
        "\n",
        "    # 計算每個段落開始的單詞索引\n",
        "    for segment in segments[:-1]:  # 排除最後一段空行\n",
        "        num_words = len(segment.split())\n",
        "        start_idx += num_words\n",
        "        segment_indices.append(start_idx)\n",
        "\n",
        "\n",
        "    # 確定哪些段落要被保留\n",
        "    sentence_count=0\n",
        "    each_sentence_score = []\n",
        "    segment_length_list = []\n",
        "    for i in range(len(segment_indices) - 1):\n",
        "      start = segment_indices[i]\n",
        "      end = segment_indices[i + 1]\n",
        "      segment_match_count = sum(matched_indices[start:end])\n",
        "      segment_length = end - start\n",
        "      segment_length_list.append(segment_length)\n",
        "\n",
        "      score = segment_match_count / segment_length\n",
        "      each_sentence_score.append(score)\n",
        "      print(score, reference_words[start:end])\n",
        "      sentence_count+=1\n",
        "\n",
        "\n",
        "    kept_segments = []\n",
        "    limit = round(sum(each_sentence_score)/sentence_count,2)\n",
        "    for i in range(len(segment_indices) - 1):\n",
        "      if segment_length_list[i] > 0 and each_sentence_score[i] > limit:\n",
        "        kept_segments.append(segments[i].strip())\n",
        "\n",
        "    return kept_segments, limit\n"
      ],
      "metadata": {
        "id": "Nv4TqHHT5Qsi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#以句點切斷，看每段中predict出現的次數，如果段中平均超過limit則留下那段\n",
        "def after_process(abstract, predicted_list):\n",
        "  # reference = abstract\n",
        "  reference = abstract\n",
        "\n",
        "  print(reference)\n",
        "\n",
        "  reference_words = reference.split()\n",
        "  matched_indices = [0] * len(reference_words)\n",
        "\n",
        "\n",
        "  for predicted in predicted_list:\n",
        "    reg = build_reference_array(reference, predicted)\n",
        "    for i in range(len(reg)):\n",
        "      matched_indices[i] += reg[i]\n",
        "\n",
        "\n",
        "  kept_segments, limit = segment_and_filter_with_average(reference, matched_indices)\n",
        "  print()\n",
        "  print(f\"Kept segments where average matches > {limit}:\")\n",
        "\n",
        "  last_predict = \"\"\n",
        "\n",
        "  for segment in kept_segments:\n",
        "      last_predict = last_predict + segment + \". \"\n",
        "\n",
        "  return last_predict\n",
        "\n",
        "# print(last_predict)"
      ],
      "metadata": {
        "id": "QjLC_x4uTWWt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scorer.score(reference, last_predict)['rougeL'].fmeasure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0f934bdd-859b-47a6-ab2a-3190faa99091",
        "id": "MgCbv6ahTbjK"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scorer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-779bad4df46c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rougeL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmeasure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scorer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenELM-450M_finetune with TRL (Not Use)"
      ],
      "metadata": {
        "id": "PnNdmsUwQCJe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQoNuD2mqFrZ",
        "outputId": "3fe5d90b-4b08-44ef-9643-04f41aceef6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.41.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.31.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.19.2)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.23.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.4)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
            "Requirement already satisfied: wandb==0.16.6 in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (2.5.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.6) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.16.6) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.6) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.6) (2024.6.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.6) (5.0.1)\n",
            "Requirement already satisfied: bitsandbytes==0.43.1 in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.1) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.1) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.1) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes==0.43.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes==0.43.1) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip install trl\n",
        "# !pip install wandb==0.16.6\n",
        "# !pip install bitsandbytes==0.43.1\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emiVnuqp6TeK",
        "outputId": "b0de136c-2781-43c7-903d-6accc3da611b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['messages'],\n",
            "        num_rows: 76\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['messages'],\n",
            "        num_rows: 19\n",
            "    })\n",
            "})\n",
            "{'messages': [{'content': '  In September 2017, the IceCube Neutrino Observatory recorded a\\nvery-high-energy neutrino in directional coincidence with a blazar in an\\nunusually bright gamma-ray state, TXS0506+056. Blazars are prominent photon\\nsources in the universe because they harbor a relativistic jet whose radiation\\nis strongly collimated and amplified. High-energy atomic nuclei known as cosmic\\nrays can produce neutrinos; thus the recent detection may help identifying the\\nsources of the diffuse neutrino flux and the energetic cosmic rays. Here we\\nreport on a self-consistent analysis of the physical relation between the\\nobserved neutrino and the blazar, in particular the time evolution and spectral\\nbehavior of neutrino and photon emission. We demonstrate that a moderate\\nenhancement in the number of cosmic rays during the flare can yield a very\\nstrong increase of the neutrino flux which is limited by co-produced hard\\nX-rays and TeV gamma rays. We also test typical radiation models for\\ncompatibility and identify several model classes as incompatible with the\\nobservations. We investigate to what degree the findings can be generalized to\\nthe entire population of blazars, to determine the relation between their\\noutput in photons, neutrinos, and cosmic rays, and suggest how to optimize the\\nstrategy of future observations.\\n', 'role': 'user'}, {'content': 'This study explores the connection between observed neutrinos and blazars by analyzing their temporal and spectral characteristics. The analysis demonstrates that a moderate increase in cosmic rays during a blazar flare can lead to a significant surge in neutrino flux, constrained by the simultaneous production of hard X-rays and TeV gamma rays. The study further assesses the compatibility of various radiation models with the observed data, identifying several model classes that contradict the observations. The findings are then generalized to the broader population of blazars, aiming to understand the relationship between their output in photons, neutrinos, and cosmic rays. The study concludes by proposing strategies for optimizing future observations. \\n', 'role': 'assistant'}]}\n"
          ]
        }
      ],
      "source": [
        "# from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# dataset = load_dataset('csv', data_files=\"output.csv\", split=\"all\")\n",
        "\n",
        "# def create_conversation(sample):\n",
        "#   return {\n",
        "#     \"messages\": [\n",
        "#       {\"role\": \"user\", \"content\": sample[\"Abstract\"]},\n",
        "#       {\"role\": \"assistant\", \"content\": sample[\"Metholodgy_LLM\"]}\n",
        "#     ]\n",
        "#   }\n",
        "\n",
        "# dataset = dataset.map(create_conversation, remove_columns=dataset.features)\n",
        "# dataset = dataset.train_test_split(test_size=0.2)\n",
        "# print(dataset)\n",
        "# print(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# import torch\n",
        "# from transformers import TrainingArguments, set_seed, get_constant_schedule\n",
        "# from trl import SFTTrainer, setup_chat_format, DataCollatorForCompletionOnlyLM\n",
        "# from datasets import load_dataset\n",
        "# import uuid, wandb\n",
        "\n",
        "# set_seed(0)\n",
        "# lr = 5e-5\n",
        "# run_id = f\"OpenELM-1_1B-Instruct_LR-{lr}_OA_{str(uuid.uuid4())}\"\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     \"apple/OpenELM-1_1B-Instruct\",\n",
        "#     trust_remote_code=True,\n",
        "#     device_map = None,\n",
        "#     torch_dtype = torch.bfloat16,\n",
        "#     )\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\n",
        "#     \"meta-llama/Llama-2-7b-hf\",\n",
        "#     use_fast=False)\n",
        "\n",
        "# model, tokenizer = setup_chat_format(model, tokenizer)\n",
        "# if tokenizer.pad_token in [None, tokenizer.eos_token]:\n",
        "#       tokenizer.pad_token = tokenizer.unk_token\n",
        "\n",
        "\n",
        "\n",
        "# training_arguments = TrainingArguments(\n",
        "#       output_dir = \"./result\",\n",
        "#       evaluation_strategy = \"steps\",\n",
        "#       label_names = [\"labels\"],\n",
        "#       per_device_train_batch_size = 8,\n",
        "#       gradient_accumulation_steps = 2,\n",
        "#       save_steps = 250,\n",
        "#       eval_steps = 250,\n",
        "#       logging_steps = 1,\n",
        "#       learning_rate = lr,\n",
        "#       num_train_epochs = 1,\n",
        "#       lr_scheduler_type = \"constant\",\n",
        "#       optim = 'paged_adamw_8bit',\n",
        "#       bf16 = True,\n",
        "#       gradient_checkpointing = True,\n",
        "#       group_by_length = True,\n",
        "#   )\n",
        "\n",
        "# trainer = SFTTrainer(\n",
        "#       model = model,\n",
        "#       tokenizer = tokenizer,\n",
        "#       train_dataset = dataset[\"train\"],\n",
        "#       eval_dataset = dataset['test'],\n",
        "#       data_collator = DataCollatorForCompletionOnlyLM(\n",
        "#           instruction_template = \"<|im_start|>user\",\n",
        "#           response_template = \"<|im_start|>assistant\",\n",
        "#           tokenizer = tokenizer,\n",
        "#           mlm = False),\n",
        "#       max_seq_length = 2048,\n",
        "#       dataset_kwargs = dict(add_special_tokens = False),\n",
        "#       args = training_arguments,\n",
        "#   )\n",
        "\n",
        "# wandb.init(\n",
        "#     project = \"OpenELM\",\n",
        "#     name = run_id,\n",
        "# ).log_code(include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
        "\n",
        "\n",
        "# trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934,
          "referenced_widgets": [
            "acc258704b5744d08b4d192597b557ba",
            "d6296b179129407f967041434719f814",
            "a0528d7d9ebe42cc9a98e339b408824b",
            "10e5b30c57e54f0fb68397f3c32a476c",
            "6fcb879f608441deafef0a0061edd0f8",
            "d09ee6463e814779acc0cd647191e1d0",
            "218bbd375b4f4304beed2e99723817b1",
            "929884f4531940b18ccaf78209e7a6d6"
          ]
        },
        "outputId": "4fb23590-886c-47ac-b95a-47d7dd19b974",
        "id": "1tw6a0uBRTo2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:355: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:bjax26sl) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acc258704b5744d08b4d192597b557ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▂▃▃▄▄▅▅▅▆▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>899530418380800.0</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>15</td></tr><tr><td>train/grad_norm</td><td>3.01562</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>train/loss</td><td>0.8524</td></tr><tr><td>train_loss</td><td>3.51228</td></tr><tr><td>train_runtime</td><td>570.3702</td></tr><tr><td>train_samples_per_second</td><td>0.4</td></tr><tr><td>train_steps_per_second</td><td>0.026</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">OpenELM-1_1B-Instruct_LR-5e-05_OA_8222942c-0d0f-49da-b73d-4880024f40ab</strong> at: <a href='https://wandb.ai/yuu23/OpenELM/runs/bjax26sl' target=\"_blank\">https://wandb.ai/yuu23/OpenELM/runs/bjax26sl</a><br/> View project at: <a href='https://wandb.ai/yuu23/OpenELM' target=\"_blank\">https://wandb.ai/yuu23/OpenELM</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_135542-bjax26sl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:bjax26sl). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.17.1 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240612_143356-objbzg6y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yuu23/OpenELM/runs/objbzg6y' target=\"_blank\">OpenELM-1_1B-Instruct_LR-5e-05_OA_ae0463d3-b9f9-4df9-9f70-4c14dab9dd28</a></strong> to <a href='https://wandb.ai/yuu23/OpenELM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yuu23/OpenELM' target=\"_blank\">https://wandb.ai/yuu23/OpenELM</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yuu23/OpenELM/runs/objbzg6y' target=\"_blank\">https://wandb.ai/yuu23/OpenELM/runs/objbzg6y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No relevant files were detected in the specified directory. No code will be logged to your run.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 02:32, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5, training_loss=8.169578742980956, metrics={'train_runtime': 191.0216, 'train_samples_per_second': 0.398, 'train_steps_per_second': 0.026, 'total_flos': 299364697018368.0, 'train_loss': 8.169578742980956, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = \"model_name\"\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_path,\n",
        "#     trust_remote_code=True,\n",
        "#     device_map=None\n",
        "# )"
      ],
      "metadata": {
        "id": "GGjJV_-mZ_D_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "874d7b2f-4718-443d-8772-c1281cdc1869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/content/result/runs/Jun12_13-17-47_01fef0d31863 does not appear to have a file named config.json. Checkout 'https://huggingface.co//content/result/runs/Jun12_13-17-47_01fef0d31863/tree/None' for available files.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-99ab9c98f775>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/result/runs/Jun12_13-17-47_01fef0d31863\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    524\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    690\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_raise_exceptions_for_missing_entries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 raise EnvironmentError(\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0;34mf\"{path_or_repo_id} does not appear to have a file named {full_filename}. Checkout \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0;34mf\"'https://huggingface.co/{path_or_repo_id}/tree/{revision}' for available files.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /content/result/runs/Jun12_13-17-47_01fef0d31863 does not appear to have a file named config.json. Checkout 'https://huggingface.co//content/result/runs/Jun12_13-17-47_01fef0d31863/tree/None' for available files."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhp5RqR_b484"
      },
      "outputs": [],
      "source": [
        "# def extract_sentence(abstract: str) -> str:\n",
        "#     # # 0.4044943820224719\n",
        "#     # prompt = \"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` \\n Don't predict line breaks and other information\" % abstract\n",
        "\n",
        "#     # # 0.4122137404580153\n",
        "#     # prompt = \"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` \\n Don't predict line breaks and other information\" % abstract\n",
        "\n",
        "#     # # 0.5668449197860963\n",
        "#     # prompt = \"From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```%s``` \\nDon't predict line breaks and other information\" % abstract\n",
        "\n",
        "#     promptList = [\"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` Don't predict line breaks\" % abstract,\n",
        "#             \"From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\\n\\n\\n```%s``` \\n Don't predict line breaks\" % abstract,\n",
        "#             \"From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```%s``` \\nDon't predict line breaks and other information\" % abstract]\n",
        "\n",
        "\n",
        "#     output_textList = []\n",
        "\n",
        "#     for index, prompt in enumerate(promptList):\n",
        "#       print(f\"==============={index}====================\")\n",
        "#       print(prompt)\n",
        "#       output_text, genertaion_time = generate(\n",
        "#           prompt=prompt,\n",
        "#           # model=\"apple/OpenELM-1_1B-Instruct\",\n",
        "#           model=trainer.model,\n",
        "#           hf_access_token=userdata.get('HF_TOKEN')\n",
        "#       )\n",
        "#       output_textList.append(output_text)\n",
        "#       print(\"================finish=================\")\n",
        "\n",
        "#     return output_textList"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "uMQXL-nCKMDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(foo):\n",
        "    import urllib.request\n",
        "    test = \"https://www.cs.nccu.edu.tw/~hhhuang/courses/nlp2024/test2024.in\"\n",
        "    gold = \"https://www.cs.nccu.edu.tw/~hhhuang/courses/nlp2024/test2024.gold\"\n",
        "\n",
        "    from rouge_score import rouge_scorer\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'])\n",
        "\n",
        "    total = 0\n",
        "    cnt = 0\n",
        "    with urllib.request.urlopen(test) as testin, \\\n",
        "         urllib.request.urlopen(gold) as gold:\n",
        "        for input, ref in zip(testin, gold):\n",
        "            input = input.decode(\"utf-8\")\n",
        "            print(f\"input = {input}\")\n",
        "            ref = ref.decode(\"utf-8\")\n",
        "            print(f\"ref = {ref}\")\n",
        "            output = foo(input)\n",
        "            print(output)\n",
        "            output = after_process(input, output)\n",
        "            score = scorer.score(ref, output)['rougeL'].fmeasure\n",
        "            cnt += 1\n",
        "            total += score\n",
        "            print(\"Test case %d: %g\" % (cnt, score))\n",
        "    print(\"Overall: %g\" % (total / cnt))\n",
        "    return total / cnt\n",
        "\n",
        "# As your working function is `extract_sentence`, so do evaluation with the following statement\n",
        "evaluate(extract_sentence)"
      ],
      "metadata": {
        "id": "J9vrVbkHKOGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05707d31-019c-4674-d6c6-3a428e6628fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = This article introduces a named entity matching model that makes use of both semantic and phonetic evidence. The matching of semantic and phonetic information is captured by a unified framework via a bipartite graph model. By considering various technical challenges of the problem, including order insensitivity and partial matching, this approach is less rigid than existing approaches and highly robust. One major component is a phonetic matching model which exploits similarity at the phoneme level. Two learning algorithms for learning the similarity information of basic phonemic matching units based on training examples are investigated. By applying the proposed named entity matching model, a mining system is developed for discovering new named entity translations from daily Web news. The system is able to discover new name translations that cannot be found in the existing bilingual dictionary.\n",
            "\n",
            "ref = The matching of semantic and phonetic information is captured by a unified framework via a bipartite graph model. By considering various technical challenges of the problem, including order insensitivity and partial matching, this approach is less rigid than existing approaches and highly robust. One major component is a phonetic matching model which exploits similarity at the phoneme level. Two learning algorithms for learning the similarity information of basic phonemic matching units based on training examples are investigated. By applying the proposed named entity matching model, a mining system is developed for discovering new named entity translations from daily Web news.\n",
            "\n",
            "===============0====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```This article introduces a named entity matching model that makes use of both semantic and phonetic evidence. The matching of semantic and phonetic information is captured by a unified framework via a bipartite graph model. By considering various technical challenges of the problem, including order insensitivity and partial matching, this approach is less rigid than existing approaches and highly robust. One major component is a phonetic matching model which exploits similarity at the phoneme level. Two learning algorithms for learning the similarity information of basic phonemic matching units based on training examples are investigated. By applying the proposed named entity matching model, a mining system is developed for discovering new named entity translations from daily Web news. The system is able to discover new name translations that cannot be found in the existing bilingual dictionary.\n",
            "``` Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============1====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```This article introduces a named entity matching model that makes use of both semantic and phonetic evidence. The matching of semantic and phonetic information is captured by a unified framework via a bipartite graph model. By considering various technical challenges of the problem, including order insensitivity and partial matching, this approach is less rigid than existing approaches and highly robust. One major component is a phonetic matching model which exploits similarity at the phoneme level. Two learning algorithms for learning the similarity information of basic phonemic matching units based on training examples are investigated. By applying the proposed named entity matching model, a mining system is developed for discovering new named entity translations from daily Web news. The system is able to discover new name translations that cannot be found in the existing bilingual dictionary.\n",
            "``` \n",
            " Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============2====================\n",
            "From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```This article introduces a named entity matching model that makes use of both semantic and phonetic evidence. The matching of semantic and phonetic information is captured by a unified framework via a bipartite graph model. By considering various technical challenges of the problem, including order insensitivity and partial matching, this approach is less rigid than existing approaches and highly robust. One major component is a phonetic matching model which exploits similarity at the phoneme level. Two learning algorithms for learning the similarity information of basic phonemic matching units based on training examples are investigated. By applying the proposed named entity matching model, a mining system is developed for discovering new named entity translations from daily Web news. The system is able to discover new name translations that cannot be found in the existing bilingual dictionary.\n",
            "``` \n",
            "Don't predict line breaks and other information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "['or word boundaries.\\n\\n1. Phonetic matching model:\\n   a. Unified framework: Captures both semantic and phonetic information.\\n   b. Technical challenges: Order insensitivity and partial matching.\\n   c. Less rigid than existing approaches: Highly robust.\\n   d. Phoneme-level similarity information: Based on training examples.\\n   e. Two learning algorithms: Supported by two matching models:\\n\\n2. Named entity matching model:\\n   a. Captures semantic information: Relationship between words and concepts.\\n   b. Technical challenges: Order insensitivity, ambiguity, and partial matching.\\n   c. Unified with phoneme matching: Less sensitive to order and partial matching.\\n   d. Supported by a bipartite graph model: Captures semantic and phonetic information.\\n   e. Two matching methods: Partial matching and semantic similarity.\\n   f. Mining system: Discover new name translations from daily Web news.\\n\\n\\n\\n```\\n\\n\\n\\n', \"; extract the sentences that shows the methods.\\n\\n```The phonetic matching model utilizes similarity information at the phoneme level. To capture this similarity, we propose two learning algorithms: (1) Phoneme-level Matching (PLM) and (2) Phoneme-level and Word-level Matching (PLWM). PLWM takes into account both phoneme similarity and word similarity.\\n\\nPLWM utilizes a multi-layer neural network with three convolutional layers and a fully connected layer. The convolutional layers learn the similarity between phonemes and words. The fully connected layer predicts the similarity score for each phoneme-word pair. PLWM then selects the most similar phoneme and word pairs for matching.\\n\\nPLM utilizes a bag-of-phonemes (BoP) model, which is a variant of BoW (Bag of Words). BoP models are widely used in Named Entity Recognition (NER) tasks due to their ability to capture the semantic similarity between words. The BoP model consists of a bag of phonemes and a vector representation of each phoneme. The vector representation is built by concatenating the phoneme's mel-spectrogram and its mel-frequency cepstral coefficients (MFCCs).\\n\\nThe BoP model is trained using a backpropagation algorithm. The similarity score between two phonemes is calculated by comparing their BoP vectors. The higher the similarity score, the closer the two phonemes are related.\\n\\nThe PLM and PLWM models are trained together with the NER model, which predicts named entity types for each input sentence. The performance of the system is measured by the F1 score, which is a weighted combination of precision and recall. The F1 score ranges from 0 to 1, where 0 indicates the sentence is not a named entity and 1 indicates the sentence is a named entity of the given entity type.\\n\\nThe experiments show that PLWM outperforms PLM and PLWM+PLNM (PLWM+phoneme-level name matching) in both NER and named entity matching tasks. PLWM+PLNM achieves an F1 score of 0.92, which is significantly higher than the F1 score of PLWM+PLNM+PLNM (PLWM+phoneme-level name matching+phoneme-level name matching) of 0.87. PLWM+PLNM+PLNM+PLNM+PLNM (PLWM+phoneme-level name matching+phoneme-level name matching+phoneme-level and word-level matching) achieves an F1 score of 0.90, which is close to the F1 score of PLWM+PLNM+PLNM+PLNM (PLWM+phoneme-level name matching+phoneme-level name matching+phoneme-level matching) of 0.91.\\n\\nThe results demonstrate that PLWM+PLNM+PLNM+PLNM+PLNM outperforms PLWM+PLNM+PLNM+PLNM (PLWM+phoneme-level name matching+phoneme-level name matching+phoneme-level matching+phoneme-level and word-level matching) by 0.01 in F1 score. This improvement can be attributed to the addition of PLNM, which improves the similarity between phonemes and words by considering the phoneme's mel-spectrogram and MFCCs.\\n\\nThe results also show that PLWM+PLNM+PLNM+PLNM+PLNM outperforms PLWM+PLNM+PLNM+PLNM+PLWM\", 'that is not discussed in the abstract, such as methods, conclusions, or results not discussed in the primary text.\\n\\n```\\nThis article introduces a named entity matching model that makes use of both semantic and phonetic evidence, where:\\n\\n* \"semantic evidence\" refers to the knowledge about the relationships between words and concepts, captured by a bipartite graph model;\\n* \"phonetic evidence\" refers to the similarity information captured by a unified framework, including order insensitivity and partial matching.\\n\\nThe proposed model aims to discover new named entity translations from daily Web news.\\n\\nThe unified framework allows the following sentences to discuss the primary results or findings of the study:\\n\\n1. \"The proposed phonetic matching model exploits similarity at the phoneme level.\"\\n2. \"The mining system developed in this article utilizes the phonetic matching model to discover new named entity translations from daily Web news.\"\\n3. \"The two learning algorithms for training the similarity information of phoneme-level matching units are investigated.\"\\n4. \"The mining system is able to discover new name translations that cannot be found in the existing bilingual dictionary.\"\\n5. \"The mining system is developed and tested on a dataset of daily Web news articles.\"\\n6. \"The mining system discovers new named entity translations related to the following topics: business, technology, and politics.\"\\n7. \"The mining system is able to discover named entity translations that are not included in the existing bilingual dictionary.\"\\n8. \"The mining system is able to discover named entity translations that are not captured by existing named entity dictionaries.\"\\n9. \"The proposed named entity matching model is applied to discover new name translations for the following named entity categories: companies, organizations, and people.\"\\n10. \"The proposed named entity matching model is applied to discover new name translations for the following named entity types: companies, organizations, and people in business, technology, and politics.\"\\n11. \"The proposed named entity matching model is highly robust and less rigid than existing approaches.\"\\n12. \"The proposed named entity matching model is highly flexible and can be extended to other languages.\"\\n13. \"The proposed named entity matching model is applied to discover new name translations for the following named entities: companies, organizations, and people in the following languages: English, Spanish, French, German, Portuguese, and Chinese.\"\\n14. \"The proposed named entity matching model is applied to discover new name translations for the following named entity categories: companies, organizations, and people in business, technology, and politics.\"\\n15. \"The proposed named entity matching model is applied to discover new name translations for the following named entity types: companies, organizations, and people in business, technology, and politics in business, technology, and politics.\"\\n16. \"The proposed named entity matching model is highly effective and efficient in discovering new named entity translations.\"\\n17. \"The proposed named entity matching model is highly effective and efficient in discovering named entity translations related to the topics and topics not included in the existing bilingual dictionary.\"\\n18. \"The proposed named entity matching model is highly effective and efficient in discovering named entity translations related to the named entity categories and named entity types not captured by existing named entity dictionaries.\"\\n19. \"The proposed named entity matching model is highly effective and efficient in discovering named entity translations related to the languages not captured by existing named entity dictionaries for English, Spanish, French, German, Portuguese, and Chinese.\"\\n20. \"The proposed named entity matching model is highly effective and efficient in discovering named entity translations related to the following topics: business, technology, and politics.\"\\n21']\n",
            "This article introduces a named entity matching model that makes use of both semantic and phonetic evidence. The matching of semantic and phonetic information is captured by a unified framework via a bipartite graph model. By considering various technical challenges of the problem, including order insensitivity and partial matching, this approach is less rigid than existing approaches and highly robust. One major component is a phonetic matching model which exploits similarity at the phoneme level. Two learning algorithms for learning the similarity information of basic phonemic matching units based on training examples are investigated. By applying the proposed named entity matching model, a mining system is developed for discovering new named entity translations from daily Web news. The system is able to discover new name translations that cannot be found in the existing bilingual dictionary.\n",
            "\n",
            "1.588235294117647 ['This', 'article', 'introduces', 'a', 'named', 'entity', 'matching', 'model', 'that', 'makes', 'use', 'of', 'both', 'semantic', 'and', 'phonetic', 'evidence.']\n",
            "0.7222222222222222 ['The', 'matching', 'of', 'semantic', 'and', 'phonetic', 'information', 'is', 'captured', 'by', 'a', 'unified', 'framework', 'via', 'a', 'bipartite', 'graph', 'model.']\n",
            "0.88 ['By', 'considering', 'various', 'technical', 'challenges', 'of', 'the', 'problem,', 'including', 'order', 'insensitivity', 'and', 'partial', 'matching,', 'this', 'approach', 'is', 'less', 'rigid', 'than', 'existing', 'approaches', 'and', 'highly', 'robust.']\n",
            "0.9333333333333333 ['One', 'major', 'component', 'is', 'a', 'phonetic', 'matching', 'model', 'which', 'exploits', 'similarity', 'at', 'the', 'phoneme', 'level.']\n",
            "0.8947368421052632 ['Two', 'learning', 'algorithms', 'for', 'learning', 'the', 'similarity', 'information', 'of', 'basic', 'phonemic', 'matching', 'units', 'based', 'on', 'training', 'examples', 'are', 'investigated.']\n",
            "1.173913043478261 ['By', 'applying', 'the', 'proposed', 'named', 'entity', 'matching', 'model,', 'a', 'mining', 'system', 'is', 'developed', 'for', 'discovering', 'new', 'named', 'entity', 'translations', 'from', 'daily', 'Web', 'news.']\n",
            "1.2222222222222223 ['The', 'system', 'is', 'able', 'to', 'discover', 'new', 'name', 'translations', 'that', 'cannot', 'be', 'found', 'in', 'the', 'existing', 'bilingual', 'dictionary.']\n",
            "\n",
            "Kept segments where average matches > 1.06:\n",
            "Test case 1: 0.35443\n",
            "input = We present a method for creating a comparable text corpus from two document collections in different languages. The collections can be very different in origin. In this study, we build a comparable corpus from articles by a Swedish news agency and a U.S. newspaper. The keys with best resolution power were extracted from the documents of one collection, the source collection, by using the relative average term frequency (RATF) value. The keys were translated into the language of the other collection, the target collection, with a dictionary-based query translation program. The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria. The resulting comparable collection was used as a similarity thesaurus to translate queries along with a dictionary-based translator. The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone.\n",
            "\n",
            "ref = The collections can be very different in origin. In this study, we build a comparable corpus from articles by a Swedish news agency and a U.S. newspaper. The keys with best resolution power were extracted from the documents of one collection, the source collection, by using the relative average term frequency (RATF) value. The keys were translated into the language of the other collection, the target collection, with a dictionary-based query translation program. The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria. The resulting comparable collection was used as a similarity thesaurus to translate queries along with a dictionary-based translator.\n",
            "\n",
            "===============0====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```We present a method for creating a comparable text corpus from two document collections in different languages. The collections can be very different in origin. In this study, we build a comparable corpus from articles by a Swedish news agency and a U.S. newspaper. The keys with best resolution power were extracted from the documents of one collection, the source collection, by using the relative average term frequency (RATF) value. The keys were translated into the language of the other collection, the target collection, with a dictionary-based query translation program. The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria. The resulting comparable collection was used as a similarity thesaurus to translate queries along with a dictionary-based translator. The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone.\n",
            "``` Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============1====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```We present a method for creating a comparable text corpus from two document collections in different languages. The collections can be very different in origin. In this study, we build a comparable corpus from articles by a Swedish news agency and a U.S. newspaper. The keys with best resolution power were extracted from the documents of one collection, the source collection, by using the relative average term frequency (RATF) value. The keys were translated into the language of the other collection, the target collection, with a dictionary-based query translation program. The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria. The resulting comparable collection was used as a similarity thesaurus to translate queries along with a dictionary-based translator. The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone.\n",
            "``` \n",
            " Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============2====================\n",
            "From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```We present a method for creating a comparable text corpus from two document collections in different languages. The collections can be very different in origin. In this study, we build a comparable corpus from articles by a Swedish news agency and a U.S. newspaper. The keys with best resolution power were extracted from the documents of one collection, the source collection, by using the relative average term frequency (RATF) value. The keys were translated into the language of the other collection, the target collection, with a dictionary-based query translation program. The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria. The resulting comparable collection was used as a similarity thesaurus to translate queries along with a dictionary-based translator. The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone.\n",
            "``` \n",
            "Don't predict line breaks and other information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "['\\n\\n```\\n1: Key: date\\n2: Method: Query-Translation-Alignment\\n3: Abstract:\\n\\n2: Text:\\n\\n  2.1: Key: Translation-Aligning-Query-Program\\n  2.2: Method: Dictionary-Based-Query-Translation\\n  2.3: Abstract:\\n\\n  2.3.1: RATF: Relative Average Term Frequency\\n  2.3.2: Target Collection: U.S. Newspaper\\n  2.3.3: Source Collection: Swedish News Agency Article Database\\n  2.3.4: Date Matching Criteria: Newspaper articles published within the last 12 months\\n  2.3.5: Translation Program: TermFreq\\n  2.3.6: Translation Algorithm: Maximum Aligned Terms (MAT)\\n  2.3.7: Translation Queries: TermFreq-Matched Query Program\\n  2.3.8: Alignment Pair: Target Collection and Source Collection\\n  2.3.9: Alignment Score: Term Frequency Alignment Quality (TF-AQ)\\n  2.3.10: Alignment Precision: Term Frequency Alignment Precision (TF-AP)\\n\\n  2.4: Findings:\\n     2.4.1: Comparable Text Corpus: 95% similarity\\n     2.4.2: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries\\n     2.4.3: Translation Algorithm: MAT outperforms RATF and Term Frequency Average (TFA)\\n     2.4.4: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x\\n     2.4.5: Target Collection: Higher TF-AP than the Source Collection\\n     2.4.6: Source Collection: Lower TF-AP than the Target Collection\\n     2.4.7: Date Matching: Aligned Queries Perform Better than Non-Aligned Queries\\n     2.4.8: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x\\n     2.4.9: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x (cont.)\\n     2.4.10: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x (cont.) (2)\\n\\n  2.5: Implications:\\n     2.5.1: Comparable Text Corpus: Enhanced Text Retrieval Accuracy\\n     2.5.2: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x (cont.)\\n     2.5.3: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x (cont.) (3)\\n     2.5.4: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x (cont.) (4)\\n     2.5.5: Translation Queries: Translation-Aligned Queries Outperform Non-Aligned Queries by 2.5-3x (cont.) (5)\\n     2.5.6', ':\\n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<', \"found within the abstract, such as authors, affiliations, or conclusions.\\n\\n```\\nWe present a method for creating a comparable text corpus from two document collections in different languages, where:\\n\\n1. `The keys` are the terms extracted from the source collection documents and used as queries in the target collection to retrieve text documents.\\n2. `The keys' translations` are performed by using a dictionary-based query-translation program.\\n3. `The translated queries` are run against the target collection text documents.\\n4. `The resulting comparable corpus` is used as a similarity thesaurus to translate queries along with a dictionary-based translator.\\n\\nThe extracted sentences are as follows:\\n\\n1. `The keys were extracted from the source collection documents by using the relative average term frequency (RATF) value.`\\n   - `The RATF value measures the term's frequency in the source collection against the frequency of all terms in the target collection.`\\n   - `The higher the RATF value, the more similar the terms in the two collections are.`\\n\\n2. `The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria.`\\n   - `The date criterion specifies the minimum number of days between the query and target document retrievals.`\\n   - `The similarity score criterion measures the similarity between the terms in the two documents.`\\n\\n3. `The translated queries were aligned with the target documents using a dictionary-based translator.`\\n   - `The dictionary-based translator translates the target document terms into the target collection terms.`\\n   - `The translator is a statistical model that takes into account the target document's context and the target collection's term frequency distribution.`\\n\\n4. `The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone.`\\n   - `The translation schemes with dictionary-based translation or corpus translation alone outperformed the translation scheme with the dictionary-based translator alone.`\\n   - `The combination of dictionary-based translation and translator outperformed the combination of translation schemes with dictionary-based translation alone and corpus translation alone.`\\n\\nThe abstract mentions the following sentences:\\n\\n1. `The RATF value indicates that the terms extracted from the source collection documents are highly related to the terms in the target collection.`\\n   - `The extracted terms are related because they share similar meanings and are frequently used interchangeably in the source and target collections.`\\n   - `The extracted terms are also related because they share high similarity with each other and with the target collection's terms.`\\n\\n2. `The translated queries and the target documents matched the alignment criteria because the target collection terms were translated into the target collection terms with high accuracy.`\\n   - `The translator accurately translated target collection terms into target collection terms because the target collection terms' term frequency distributions matched the target collection's term frequency distribution.`\\n   - `The translator's high accuracy in matching terms with given alignment criteria indicates that the translator accurately translated the target collection terms into the target collection terms.`\\n\\n3. `The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone because the translator improved the translation quality.`\\n   - `The translation schemes with dictionary-based translation or corpus translation alone outperformed the translation scheme with the dictionary-based translator alone because the translator's quality was not as high as the translator's performance in the combined approaches.`\\n   - `The combined approaches outperformed translation schemes with poorer translator performance because the translator improved\"]\n",
            "We present a method for creating a comparable text corpus from two document collections in different languages. The collections can be very different in origin. In this study, we build a comparable corpus from articles by a Swedish news agency and a U.S. newspaper. The keys with best resolution power were extracted from the documents of one collection, the source collection, by using the relative average term frequency (RATF) value. The keys were translated into the language of the other collection, the target collection, with a dictionary-based query translation program. The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria. The resulting comparable collection was used as a similarity thesaurus to translate queries along with a dictionary-based translator. The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone.\n",
            "\n",
            "1.0 ['We', 'present', 'a', 'method', 'for', 'creating', 'a', 'comparable', 'text', 'corpus', 'from', 'two', 'document', 'collections', 'in', 'different', 'languages.']\n",
            "0.25 ['The', 'collections', 'can', 'be', 'very', 'different', 'in', 'origin.']\n",
            "0.3333333333333333 ['In', 'this', 'study,', 'we', 'build', 'a', 'comparable', 'corpus', 'from', 'articles', 'by', 'a', 'Swedish', 'news', 'agency', 'and', 'a', 'U.S.']\n",
            "0.0 ['newspaper.']\n",
            "1.0 ['The']\n",
            "0.7307692307692307 ['keys', 'with', 'best', 'resolution', 'power', 'were', 'extracted', 'from', 'the', 'documents', 'of', 'one', 'collection,', 'the', 'source', 'collection,', 'by', 'using', 'the', 'relative', 'average', 'term', 'frequency', '(RATF)', 'value.', 'The']\n",
            "0.35 ['keys', 'were', 'translated', 'into', 'the', 'language', 'of', 'the', 'other', 'collection,', 'the', 'target', 'collection,', 'with', 'a', 'dictionary-based', 'query', 'translation', 'program.', 'The']\n",
            "1.0769230769230769 ['translated', 'queries', 'were', 'run', 'against', 'the', 'target', 'collection', 'and', 'an', 'alignment', 'pair', 'was', 'made', 'if', 'the', 'retrieved', 'documents', 'matched', 'given', 'date', 'and', 'similarity', 'score', 'criteria.', 'The']\n",
            "0.4444444444444444 ['resulting', 'comparable', 'collection', 'was', 'used', 'as', 'a', 'similarity', 'thesaurus', 'to', 'translate', 'queries', 'along', 'with', 'a', 'dictionary-based', 'translator.', 'The']\n",
            "0.9333333333333333 ['combined', 'approaches', 'outperformed', 'translation', 'schemes', 'where', 'dictionary-based', 'translation', 'or', 'corpus', 'translation', 'was', 'used', 'alone.']\n",
            "\n",
            "Kept segments where average matches > 0.61:\n",
            "Test case 2: 0.592233\n",
            "input = Web search engines typically provide search results without considering user interests or context. We propose a personalized search approach that can easily extend a conventional search engine on the client side. Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests. In two sets of controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length. We find that PCAT is preferable to LIST for information gathering types of tasks and for searches with short queries, and PCAT outperforms CAT in both information gathering and finding types of tasks, and for searches associated with free-form queries. From the subjects' answers to a questionnaire, we find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.\n",
            "\n",
            "ref = Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests. In two sets of controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length.\n",
            "\n",
            "===============0====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```Web search engines typically provide search results without considering user interests or context. We propose a personalized search approach that can easily extend a conventional search engine on the client side. Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests. In two sets of controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length. We find that PCAT is preferable to LIST for information gathering types of tasks and for searches with short queries, and PCAT outperforms CAT in both information gathering and finding types of tasks, and for searches associated with free-form queries. From the subjects' answers to a questionnaire, we find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.\n",
            "``` Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============1====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```Web search engines typically provide search results without considering user interests or context. We propose a personalized search approach that can easily extend a conventional search engine on the client side. Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests. In two sets of controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length. We find that PCAT is preferable to LIST for information gathering types of tasks and for searches with short queries, and PCAT outperforms CAT in both information gathering and finding types of tasks, and for searches associated with free-form queries. From the subjects' answers to a questionnaire, we find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.\n",
            "``` \n",
            " Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============2====================\n",
            "From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```Web search engines typically provide search results without considering user interests or context. We propose a personalized search approach that can easily extend a conventional search engine on the client side. Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests. In two sets of controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length. We find that PCAT is preferable to LIST for information gathering types of tasks and for searches with short queries, and PCAT outperforms CAT in both information gathering and finding types of tasks, and for searches associated with free-form queries. From the subjects' answers to a questionnaire, we find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.\n",
            "``` \n",
            "Don't predict line breaks and other information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "['\\n<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<', \":\\n\\n```\\n1: Automatically map user interests onto categories in the Open Directory Project (ODP)\\n2: Use manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests\\n3: Compare personalized categorization system (PCAT) with list interface system (LIST) and nonpersonalized categorization system (CAT)\\n4: Evaluate system performances on the basis of the type of task, query length, and task-related factors\\n5: Analyze system preferences, performance, and user satisfaction using a questionnaire\\n\\n```\\n\\n\\n```Extracted sentences\\n\\n1: Automatically map user interests onto categories in the Open Directory Project (ODP)\\n2: Use manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results\\n3: Compare personalized categorization system (PCAT) with list interface system (LIST) and nonpersonalized categorization system (CAT)\\n4: Evaluate system performances on the basis of the type of task, query length, and task-related factors\\n5: Analyze system preferences, performance, and user satisfaction using a questionnaire\\n\\n```\\n\\n2: Use manually edited data available in ODP for training text classifiers\\n   a: Manually edited data refers to the addition, deletion, or modification of entries in the Open Directory Project (ODP) by users or administrators.\\n\\n3: Compare personalized categorization system (PCAT) with list interface system (LIST) and nonpersonalized categorization system (CAT)\\n   a: Personalized categorization system (PCAT) is a method that automatically maps user interests onto categories in the ODP.\\n   b: List interface system (LIST) is a conventional search engine that uses manually edited data available in ODP for searching.\\n   c: Nonpersonalized categorization system (CAT) is a traditional categorization method that does not consider user interests.\\n\\n4: Evaluate system performances on the basis of the type of task, query length, and task-related factors\\n   a: System performances are measured in terms of finding relevant Web pages quicker and easier, information gathering, and task-related factors.\\n   b: Finding relevant Web pages quicker and easier refers to the speed and accuracy of finding relevant Web pages.\\n   c: Information gathering refers to the ability to retrieve and extract relevant information from the Web.\\n   d: Task-related factors refer to factors related to the task, such as the time spent on the search and the number of relevant Web pages found.\\n\\n5: Analyze system preferences, performance, and user satisfaction using a questionnaire\\n   a: A questionnaire is a tool used to gather information about the users' opinions, preferences, and satisfaction with a product or service.\\n   b: System preferences refer to the users' subjective opinions and preferences about the system.\\n   c: System performance measures the efficiency, accuracy, and effectiveness of the system.\\n   d: User satisfaction measures the users' subjective satisfaction with the system.\\n\\n6: Analyze system preferences, performance, and user satisfaction using a questionnaire (cont'd)\\n   a: The questionnaire asked about the following factors:\\n     1: Ease of use\\n\", \":\\n\\n```\\n1. A Personalized Search Approach that Extends a Conventional Search Engine on the Client Side\\n2. A Comparative Evaluation of Personalized Categorization System (PCAT), List Interface System (LIST), and Nonpersonalized Categorization System (CAT)\\n\\nAbstract\\n\\nSearch engines typically provide search results without considering user interests or context. To address this limitation, we propose a personalized search approach that extends a conventional search engine on the client side. Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests.\\n\\nKeywords: Personalized search, interest-based categorization, online personalization, Open Directory Project (ODP)\\n\\nINTRODUCTION\\n\\nThe traditional search engine paradigm often fails to consider user interests and context, leading to poorly targeted and irrelevant search results (Bradley & Hovy, 1998). To address this issue, we propose a personalized categorization system (PCAT) that extends a conventional search engine on the client side. Our approach leverages manually edited data available in the Open Directory Project (ODP) to map user interests onto a group of categories.\\n\\nSystem Evaluation\\n\\n2.1 Controlled Experiments\\n\\nIn two controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length.\\n\\n2.2 Subjects' Evaluation\\n\\nTo assess the usability of our system, we also conducted a questionnaire study. We find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.\\n\\n3 MAIN RESULTS\\n\\n3.1 User Interests Mapping\\n\\nWe map 12 user interests onto 12 categories in the ODP. The categories are manually edited by human experts, and they are related to topics such as sports, music, and entertainment.\\n\\n3.2 Search Tasks and System Evaluation\\n\\nIn controlled experiments, we compare the performance of PCAT with LIST and CAT on three different tasks: information gathering, finding, and free-form queries. We find that PCAT outperforms LIST and CAT in both information gathering and finding tasks, and it outperforms LIST in searches associated with free-form queries.\\n\\n3.3 System Evaluation on Subjects' Evaluation\\n\\nWe also analyze the usability of our system by conducting a questionnaire study. We find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.\\n\\n4 CONCLUSION\\n\\n4.1 Future Work\\n\\nWe plan to extend our system to support multiple user interests and to incorporate user feedback into the categorization process.\\n\\n4.2 Impact on Search Engines\\n\\nOur approach could be extended to other search engines, such as Google, to personalize their results according to user\"]\n",
            "Web search engines typically provide search results without considering user interests or context. We propose a personalized search approach that can easily extend a conventional search engine on the client side. Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests. In two sets of controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length. We find that PCAT is preferable to LIST for information gathering types of tasks and for searches with short queries, and PCAT outperforms CAT in both information gathering and finding types of tasks, and for searches associated with free-form queries. From the subjects' answers to a questionnaire, we find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.\n",
            "\n",
            "1.0 ['Web', 'search', 'engines', 'typically', 'provide', 'search', 'results', 'without', 'considering', 'user', 'interests', 'or', 'context.']\n",
            "0.7777777777777778 ['We', 'propose', 'a', 'personalized', 'search', 'approach', 'that', 'can', 'easily', 'extend', 'a', 'conventional', 'search', 'engine', 'on', 'the', 'client', 'side.']\n",
            "1.64 ['Our', 'mapping', 'framework', 'automatically', 'maps', 'a', 'set', 'of', 'known', 'user', 'interests', 'onto', 'a', 'group', 'of', 'categories', 'in', 'the', 'Open', 'Directory', 'Project', '(ODP)', 'and', 'takes', 'advantage', 'of', 'manually', 'edited', 'data', 'available', 'in', 'ODP', 'for', 'training', 'text', 'classifiers', 'that', 'correspond', 'to,', 'and', 'therefore', 'categorize', 'and', 'personalize', 'search', 'results', 'according', 'to', 'user', 'interests.']\n",
            "1.375 ['In', 'two', 'sets', 'of', 'controlled', 'experiments,', 'we', 'compare', 'our', 'personalized', 'categorization', 'system', '(PCAT)', 'with', 'a', 'list', 'interface', 'system', '(LIST)', 'that', 'mimics', 'a', 'typical', 'search', 'engine', 'and', 'with', 'a', 'nonpersonalized', 'categorization', 'system', '(CAT).']\n",
            "1.6666666666666667 ['In', 'both', 'experiments,', 'we', 'analyze', 'system', 'performances', 'on', 'the', 'basis', 'of', 'the', 'type', 'of', 'task', 'and', 'query', 'length.']\n",
            "1.075 ['We', 'find', 'that', 'PCAT', 'is', 'preferable', 'to', 'LIST', 'for', 'information', 'gathering', 'types', 'of', 'tasks', 'and', 'for', 'searches', 'with', 'short', 'queries,', 'and', 'PCAT', 'outperforms', 'CAT', 'in', 'both', 'information', 'gathering', 'and', 'finding', 'types', 'of', 'tasks,', 'and', 'for', 'searches', 'associated', 'with', 'free-form', 'queries.']\n",
            "1.1379310344827587 ['From', 'the', \"subjects'\", 'answers', 'to', 'a', 'questionnaire,', 'we', 'find', 'that', 'PCAT', 'is', 'perceived', 'as', 'a', 'system', 'that', 'can', 'find', 'relevant', 'Web', 'pages', 'quicker', 'and', 'easier', 'than', 'LIST', 'and', 'CAT.']\n",
            "\n",
            "Kept segments where average matches > 1.24:\n",
            "Test case 3: 1\n",
            "input = The aim of this article is to produce an alternative view of the adaptive hypermedia (AH) domain from a contextually-aware open hypermedia (OH) perspective. We believe that a wide range of AH techniques can be supported with a small number of OH structures, which can be combined together to create more complex effects, possibly simplifying the development of new AH systems. In this work we reexamine Brusilovsky's taxonomy of AH techniques from a structural OH perspective. We also show that it is possible to identify and model common structures across the taxonomy of adaptive techniques. An agent-based adaptive hypermedia system called HA^3L is presented, which uses these OH structures to provide a straightforward implementation of a variety of adaptive hypermedia techniques. This enables us to reflect on the structural equivalence of many of the techniques, demonstrates the advantages of the OH approach, and can inform the design of future adaptive hypermedia systems.\n",
            "\n",
            "ref = In this work we reexamine Brusilovsky's taxonomy of AH techniques from a structural OH perspective. We also show that it is possible to identify and model common structures across the taxonomy of adaptive techniques. An agent-based adaptive hypermedia system called HA^3L is presented, which uses these OH structures to provide a straightforward implementation of a variety of adaptive hypermedia techniques.\n",
            "\n",
            "===============0====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```The aim of this article is to produce an alternative view of the adaptive hypermedia (AH) domain from a contextually-aware open hypermedia (OH) perspective. We believe that a wide range of AH techniques can be supported with a small number of OH structures, which can be combined together to create more complex effects, possibly simplifying the development of new AH systems. In this work we reexamine Brusilovsky's taxonomy of AH techniques from a structural OH perspective. We also show that it is possible to identify and model common structures across the taxonomy of adaptive techniques. An agent-based adaptive hypermedia system called HA^3L is presented, which uses these OH structures to provide a straightforward implementation of a variety of adaptive hypermedia techniques. This enables us to reflect on the structural equivalence of many of the techniques, demonstrates the advantages of the OH approach, and can inform the design of future adaptive hypermedia systems.\n",
            "``` Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============1====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```The aim of this article is to produce an alternative view of the adaptive hypermedia (AH) domain from a contextually-aware open hypermedia (OH) perspective. We believe that a wide range of AH techniques can be supported with a small number of OH structures, which can be combined together to create more complex effects, possibly simplifying the development of new AH systems. In this work we reexamine Brusilovsky's taxonomy of AH techniques from a structural OH perspective. We also show that it is possible to identify and model common structures across the taxonomy of adaptive techniques. An agent-based adaptive hypermedia system called HA^3L is presented, which uses these OH structures to provide a straightforward implementation of a variety of adaptive hypermedia techniques. This enables us to reflect on the structural equivalence of many of the techniques, demonstrates the advantages of the OH approach, and can inform the design of future adaptive hypermedia systems.\n",
            "``` \n",
            " Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============2====================\n",
            "From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```The aim of this article is to produce an alternative view of the adaptive hypermedia (AH) domain from a contextually-aware open hypermedia (OH) perspective. We believe that a wide range of AH techniques can be supported with a small number of OH structures, which can be combined together to create more complex effects, possibly simplifying the development of new AH systems. In this work we reexamine Brusilovsky's taxonomy of AH techniques from a structural OH perspective. We also show that it is possible to identify and model common structures across the taxonomy of adaptive techniques. An agent-based adaptive hypermedia system called HA^3L is presented, which uses these OH structures to provide a straightforward implementation of a variety of adaptive hypermedia techniques. This enables us to reflect on the structural equivalence of many of the techniques, demonstrates the advantages of the OH approach, and can inform the design of future adaptive hypermedia systems.\n",
            "``` \n",
            "Don't predict line breaks and other information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "[\"or new sentences.\\n\\n\\nThe abstract mentions the following methods:\\n\\n1. Brusilovsky's adaptive hypermedia (AH) taxonomy:\\n   - Adaptive techniques:\\n     - Adaptive navigation\\n     - Adaptive presentation\\n     - Adaptive content\\n     - Adaptive interaction\\n     - Adaptive learning\\n     - Adaptive presentation of information\\n     - Adaptive hypermedia\\n     - Adaptive hypermedia techniques\\n   - Structural equivalences:\\n     - Context-sensitive navigation\\n     - Context-sensitive presentation\\n     - Context-sensitive content\\n     - Context-sensitive interaction\\n     - Context-sensitive hypermedia\\n     - Context-sensitive adaptation\\n   - OH approach:\\n     - Context-sensitive ontology (CSO)\\n     - Context-sensitive object-relational mapping (OSORM)\\n     - Context-sensitive object-oriented mapping (OSOML)\\n     - Context-sensitive object-relational mapping (OSOM)\\n     - Context-sensitive object-oriented object-relational mapping (OSOOM)\\n     - Context-sensitive object-relational object-oriented mapping (OSOOOM)\\n     - Context-sensitive object-relational object-oriented object-relational mapping (OSOOOOM)\\n     - Context-sensitive object-relational object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-oriented object-orient\", \"or new sentences.\\n\\n1. The taxonomy of adaptive hypermedia techniques from an OH perspective\\n\\n  1.1 Brusilovsky's adaptive hypermedia (AH) taxonomy (1982)\\n\\n  1.1.1 Adaptive hypermedia (AH)\\n  1.1.2 Adaptive techniques\\n  1.1.3 Adaptive media\\n  1.1.4 Adaptive environments\\n  1.1.5 Adaptive hypermedia system (AHSS)\\n\\n  1.1.6 Context-sensitive hypermedia (OH)\\n  1.1.7 Context-sensitive techniques\\n  1.1.8 Context-sensitive media\\n  1.1.9 Context-sensitive environments\\n  1.1.10 Context-sensitive adaptive hypermedia system (CS-AHSS)\\n\\n  1.2 Structural equivalence between adaptive techniques from the OH and AH perspectives\\n\\n  1.2.1 Context-sensitive and adaptive media\\n  1.2.2 Context-sensitive and adaptive techniques\\n  1.2.3 Context-sensitive and adaptive environments\\n  1.2.4 Context-sensitive and adaptive hypermedia systems\\n\\n  1.3 Adaptive hypermedia and open hypermedia (OH)\\n  1.3.1 Adaptive hypermedia techniques and OH structures\\n  1.3.2 Adaptive hypermedia systems and OH structures\\n  1.3.3 OH structures that support adaptive hypermedia techniques\\n\\n  1.4 Opportunities and limitations for adaptive hypermedia systems based on OH structures\\n  1.4.1 Opportunities: simplicity, flexibility, and scalability\\n  1.4.2 Limitations: limited control, limited expressiveness, and potential inconsistency\\n\\n  1.5 Future directions for adaptive hypermedia research\\n  1.5.1 Adaptive hypermedia techniques and OH structures\\n  1.5.2 Adaptive hypermedia systems and OH structures\\n  1.5.3 Opportunities and limitations for adaptive hypermedia systems based on OH structures\\n  1.5.4 Future research directions\\n\\n  1.6 Conclusion\\n\\n  1.6.1 Adaptive hypermedia techniques and OH structures can be supported with a small number of OH structures, potentially simplifying the development of new adaptive hypermedia systems.\\n  1.6.2 The OH approach provides a structural equivalence between adaptive techniques, which can inform the design of future adaptive hypermedia systems.\\n  1.6.3 Future research directions include adaptive hypermedia techniques that rely on more complex OH structures, and the study of the interaction between adaptive hypermedia and other OH technologies.\\n\\n  1.7 References\\n\\n  1.7.1 (Brusilovsky, 1982) Brusilovsky, V. (1982). Adaptive hypermedia: a taxonomy and a survey of adaptive techniques. In: Proceedings of the 1st International Workshop on Hypermedia (pp. 1-12). ACM Press.\\n  1.7.2 (Brusilovsky and Singer, 1982) Brusilovsky, V., & Singer, R. (1982). Context-sensitive hypermedia: a taxonomy and a survey of techniques.\", 'before extraction:\\n\\n```\\nThe aim of this article is<br>\\nTo produce an alternative<br>\\nview of the adaptive<br>\\nhypermedia (AH) domain<br>\\nfrom a contextually-aware<br>\\nopen hypermedia (OH) perspective.<br>\\n\\nWe believe<br>\\nthat a wide range<br>\\nof AH techniques<br>\\ncan be supported<br>\\nwith a small<br>\\nnumber<br>\\nof OH structures<br>\\n,<br>\\nwhich<br>\\ncan<br>\\nbe<br>\\ncombined<br>\\ntogether<br>\\nto<br>\\ncreate<br>\\nmore<br>\\ncomplex<br>\\neffects<br>\\n,<br>\\npossibly<br>\\nsimplifying<br>\\nthe<br>\\ndevelopment<br>\\nof<br>\\nnew<br>\\nADAPTIVE<br>\\nhypermedia<br>\\nsystems.<br>\\n\\nIn<br>\\nthis<br>\\nwork<br>\\nwe<br>\\nreexamine<br>\\nBrusilovsky<br>\\n\\'<a href=\"Brusilovsky_Taxonomy_of_ADAPTIVE_TECHNIQUES.pdf\">Taxonomy</a>_<a href=\"Brusilovsky_ADAPTIVE_TECHNIQUES.pdf\">of<br>\\nADAPTIVE<br>\\nTECHNIques</a>_<br>\\nfrom<br>\\na<br>\\nstructural<br>\\nOH<br>\\nperspective<br>\\n,<br>\\nwe<br>\\nalso<br>\\nshow<br>\\nthat<br>\\nit<br>\\nis<br>\\npossible<br>\\nto<br>\\nidentify<br>\\nand<br>\\nmodel<br>\\ncommon<br>\\nstructures<br>\\nacross<br>\\nthe<br>\\ntaxonomy<br>\\nof<br>\\nadaptive<br>\\ntechniques<br>\\n.<br>\\n\\nAn<br>\\nagent<br>\\nbased<br>\\nadaptive<br>\\nhypermedia<br>\\nsystem<br>\\ncalled<br>\\nHA<sup>3<br>\\nL</sup>\\nis<br>\\npresented<br>\\nwhich<br>\\nuses<br>\\nthese<br>\\nOH<br>\\nstructures<br>\\nto<br>\\nprovide<br>\\na<br>\\nsimply<br>\\nimplementable<br>\\nplatform<br>\\nfor<br>\\na<br>\\nvariety<br>\\nof<br>\\nADAPTIVE<br>\\ntechniques<br>\\n.\\n```\\n']\n",
            "The aim of this article is to produce an alternative view of the adaptive hypermedia (AH) domain from a contextually-aware open hypermedia (OH) perspective. We believe that a wide range of AH techniques can be supported with a small number of OH structures, which can be combined together to create more complex effects, possibly simplifying the development of new AH systems. In this work we reexamine Brusilovsky's taxonomy of AH techniques from a structural OH perspective. We also show that it is possible to identify and model common structures across the taxonomy of adaptive techniques. An agent-based adaptive hypermedia system called HA^3L is presented, which uses these OH structures to provide a straightforward implementation of a variety of adaptive hypermedia techniques. This enables us to reflect on the structural equivalence of many of the techniques, demonstrates the advantages of the OH approach, and can inform the design of future adaptive hypermedia systems.\n",
            "\n",
            "1.3333333333333333 ['The', 'aim', 'of', 'this', 'article', 'is', 'to', 'produce', 'an', 'alternative', 'view', 'of', 'the', 'adaptive', 'hypermedia', '(AH)', 'domain', 'from', 'a', 'contextually-aware', 'open', 'hypermedia', '(OH)', 'perspective.']\n",
            "0.8108108108108109 ['We', 'believe', 'that', 'a', 'wide', 'range', 'of', 'AH', 'techniques', 'can', 'be', 'supported', 'with', 'a', 'small', 'number', 'of', 'OH', 'structures,', 'which', 'can', 'be', 'combined', 'together', 'to', 'create', 'more', 'complex', 'effects,', 'possibly', 'simplifying', 'the', 'development', 'of', 'new', 'AH', 'systems.']\n",
            "0.3333333333333333 ['In', 'this', 'work', 'we', 'reexamine', \"Brusilovsky's\", 'taxonomy', 'of', 'AH', 'techniques', 'from', 'a', 'structural', 'OH', 'perspective.']\n",
            "0.15789473684210525 ['We', 'also', 'show', 'that', 'it', 'is', 'possible', 'to', 'identify', 'and', 'model', 'common', 'structures', 'across', 'the', 'taxonomy', 'of', 'adaptive', 'techniques.']\n",
            "0.3076923076923077 ['An', 'agent-based', 'adaptive', 'hypermedia', 'system', 'called', 'HA^3L', 'is', 'presented,', 'which', 'uses', 'these', 'OH', 'structures', 'to', 'provide', 'a', 'straightforward', 'implementation', 'of', 'a', 'variety', 'of', 'adaptive', 'hypermedia', 'techniques.']\n",
            "0.3548387096774194 ['This', 'enables', 'us', 'to', 'reflect', 'on', 'the', 'structural', 'equivalence', 'of', 'many', 'of', 'the', 'techniques,', 'demonstrates', 'the', 'advantages', 'of', 'the', 'OH', 'approach,', 'and', 'can', 'inform', 'the', 'design', 'of', 'future', 'adaptive', 'hypermedia', 'systems.']\n",
            "\n",
            "Kept segments where average matches > 0.55:\n",
            "Test case 4: 0.24\n",
            "input = The rapid advancement of Internet technologies enables more and more educational institutes, companies, and government agencies to provide services, namely online services, through web portals. With hundreds of online services provided through a web portal, it is critical to design web portals, namely service portals, through which online services can be easily accessed by their consumers. This article addresses this critical issue from the perspective of service selection, that is, how to select a small number of service-links (i.e., hyperlinks pointing to online services) to be featured in the homepage of a service portal such that users can be directed to find the online services they seek most effectively. We propose a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services and formally define the service selection problem. A solution method, ServiceFinder, is then proposed. Using real-world data obtained from the Utah State Government service portal, we show that ServiceFinder outperforms both the current practice of service selection and previous algorithms for adaptive website design. We also show that the performance of ServiceFinder is close to that of the optimal solution resulting from exhaustive search.\n",
            "\n",
            "ref = We propose a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services and formally define the service selection problem. A solution method, ServiceFinder, is then proposed.\n",
            "\n",
            "===============0====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```The rapid advancement of Internet technologies enables more and more educational institutes, companies, and government agencies to provide services, namely online services, through web portals. With hundreds of online services provided through a web portal, it is critical to design web portals, namely service portals, through which online services can be easily accessed by their consumers. This article addresses this critical issue from the perspective of service selection, that is, how to select a small number of service-links (i.e., hyperlinks pointing to online services) to be featured in the homepage of a service portal such that users can be directed to find the online services they seek most effectively. We propose a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services and formally define the service selection problem. A solution method, ServiceFinder, is then proposed. Using real-world data obtained from the Utah State Government service portal, we show that ServiceFinder outperforms both the current practice of service selection and previous algorithms for adaptive website design. We also show that the performance of ServiceFinder is close to that of the optimal solution resulting from exhaustive search.\n",
            "``` Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============1====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```The rapid advancement of Internet technologies enables more and more educational institutes, companies, and government agencies to provide services, namely online services, through web portals. With hundreds of online services provided through a web portal, it is critical to design web portals, namely service portals, through which online services can be easily accessed by their consumers. This article addresses this critical issue from the perspective of service selection, that is, how to select a small number of service-links (i.e., hyperlinks pointing to online services) to be featured in the homepage of a service portal such that users can be directed to find the online services they seek most effectively. We propose a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services and formally define the service selection problem. A solution method, ServiceFinder, is then proposed. Using real-world data obtained from the Utah State Government service portal, we show that ServiceFinder outperforms both the current practice of service selection and previous algorithms for adaptive website design. We also show that the performance of ServiceFinder is close to that of the optimal solution resulting from exhaustive search.\n",
            "``` \n",
            " Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============2====================\n",
            "From the abstract provided, extract all sentences that discuss the primary results or findings of the study. Ensure that only information from the abstract is included:```The rapid advancement of Internet technologies enables more and more educational institutes, companies, and government agencies to provide services, namely online services, through web portals. With hundreds of online services provided through a web portal, it is critical to design web portals, namely service portals, through which online services can be easily accessed by their consumers. This article addresses this critical issue from the perspective of service selection, that is, how to select a small number of service-links (i.e., hyperlinks pointing to online services) to be featured in the homepage of a service portal such that users can be directed to find the online services they seek most effectively. We propose a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services and formally define the service selection problem. A solution method, ServiceFinder, is then proposed. Using real-world data obtained from the Utah State Government service portal, we show that ServiceFinder outperforms both the current practice of service selection and previous algorithms for adaptive website design. We also show that the performance of ServiceFinder is close to that of the optimal solution resulting from exhaustive search.\n",
            "``` \n",
            "Don't predict line breaks and other information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "[\"\\n\\n```The purpose of this study is to develop a method to design adaptive websites that continuously optimize user experience by selecting the most effective service-links (i.e., hyperlinks pointing to online services) to feature in the homepage of a service portal.\\n\\n1.1 Background and motivation:\\nThe rapid advancement of Internet technologies has led to the rapid growth of educational institutes, companies, and government agencies providing services through web portals. However, with hundreds of online services provided through a web portal, it is critical to design web portals, namely service portals, that are effective in guiding users to find the desired online services efficiently and effectively.\\n\\n1.2 Research problem statement:\\nTo design adaptive websites that continuously optimize user experience, we consider the problem of selecting a small number of service-links (i.e., hyperlinks pointing to online services) to be featured in the homepage of a service portal such that users can be directed to find the online services they seek most effectively.\\n\\n1.3 Research problem statement (continued):\\nFormally, the problem can be stated as:\\n\\nFind the smallest subset S of N service-links (i.e., hyperlinks pointing to online services) such that:\\n\\n1. The proportion of users directed to locate their desired online services through S is maximized.\\n2. The average number of clicks required to reach the desired online services through S is minimized.\\n\\n1.4 Research objectives:\\n1. To formalize the problem and develop a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services.\\n2. To design a solution method, ServiceFinder, that efficiently selects the smallest subset S of N service-links to maximize the effectiveness of the selected service-links in directing users to locate their desired online services.\\n3. To evaluate the performance of ServiceFinder against the optimal solution resulting from exhaustive search.\\n4. To apply ServiceFinder to Utah State Government's service portal, demonstrating its effectiveness in adapting the homepage to continuously optimize user experience.\\n\\n1.5 Research contributions:\\n1. We formalize the problem and develop a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services.\\n2. We design a solution method, ServiceFinder, that efficiently selects the smallest subset S of N service-links to maximize the effectiveness of the selected service-links in directing users to locate their desired online services.\\n3. We apply ServiceFinder to Utah State Government's service portal, demonstrating its effectiveness in adapting the homepage to continuously optimize user experience.\\n\\n2 Literature review:\\n2.1 Service selection:\\nService selection is the process of determining the most effective service-links (i.e., hyperlinks pointing to online services) to feature in a homepage of a service portal to guide users to find the desired online services efficiently and effectively.\\n\\n2.2 Adaptive websites:\\nAdaptive websites are websites that continuously optimize user experience by continuously adjusting their content, design, and interaction mechanisms based on user interaction and user preferences.\\n\\n2.3 Metrics for evaluating service selection:\\nMetrics have been proposed to measure the effectiveness of service selection algorithms. Examples\", ', but extract the sentences with the given abstract methods methods.\\n\\n```Extracting the sentences with the given methods\\n\\n1. ServiceFinder selects service-links that maximize the effectiveness of directing users to locate the desired online services.\\n\\n2. ServiceFinder measures the effectiveness of the selected service-links by comparing the number of clicks users make on the selected links with the number of clicks they make on all links in the homepage.\\n\\n3. ServiceFinder selects the service-links based on a mathematically formulated metric, Effectiveness Index (EI).\\n\\n4. Effectiveness Index measures the effectiveness of a link by considering the number of users clicking on the link and the number of users clicking on all links in the homepage.\\n\\n5. Effectiveness Index is a function of the click-through rate (CTR) and the click-through rate variance (CTRV).\\n\\n6. CTR measures the number of clicks a user makes on a link divided by the number of times the user clicks on all links in the homepage.\\n\\n7. CTRV measures the variation in click-through rate among all links in the homepage.\\n\\n8. Effectiveness Index is calculated by taking the average of CTR and CTRV for each link.\\n\\n9. ServiceFinder selects the service-links with the highest Effectiveness Index.\\n\\n10. ServiceFinder selects the service-links in a greedy fashion, that is, it selects the service-links with the highest Effectiveness Index first.\\n\\n11. ServiceFinder selects the service-links in a sequential fashion, that is, it selects the service-links in the order they appear in the abstract.\\n\\n12. ServiceFinder selects the service-links in parallel, that is, it selects the service-links in the order they appear in the code.\\n\\n13. ServiceFinder selects the service-links in parallel with the parallel algorithm, that is, ServiceFinder selects the service-links in parallel with the parallel for loop.\\n\\n14. ServiceFinder selects the service-links in parallel with the sequential algorithm, that is, ServiceFinder selects the service-links sequentially with the for-loop.\\n\\n15. ServiceFinder selects the service-links in parallel with the sequential-with-parallel algorithm, that is, ServiceFinder selects the service-links sequentially with the sequential for-loop and parallel algorithm.\\n\\n16. ServiceFinder selects the service-links in parallel with the sequential-with-sequential algorithm, that is, ServiceFinder selects the service-links sequentially with the sequential for-loop and sequential-with-parallel algorithm.\\n\\n17. ServiceFinder selects the service-links sequentially with the sequential-with-parallel-with-sequential algorithm, that is, ServiceFinder selects the service-links sequentially with the sequential for-loop, sequential algorithm, sequential-with-parallel-with-sequential algorithm, and sequential-with-sequential-with-sequential algorithm.\\n\\n18. ServiceFinder selects the service-links sequentially with the sequential-with-parallel-with-sequential-with-sequential algorithm, that is, ServiceFinder selects the service-links sequentially with the sequential for-loop, sequential-with-parallel-with', \"before extracting the sentences.\\n\\n```Extracting the sentences:\\n1. The rapid advancement of Internet technologies enables more and more educational institutes, companies, and government agencies to provide services, namely online services, through web portals.\\n2. Service selection is a mathematically formulated problem that measures the effectiveness of the selected service-links (i.e., hyperlinks pointing to online services) in directing users to locate their desired online services.\\n3. A mathematically formulated metric, the Service Selection Efficiency (SSE), is proposed to measure the effectiveness of the selected service-links.\\n4. The SSE is a function of the number of service-links, the proportion of clicks on the selected service-links, and the proportion of users who reach the desired online services.\\n5. The optimal solution for the service selection problem is the exhaustive search, where all possible combinations of clicks and users' paths are explored.\\n6. ServiceFinder, a solution method based on the exhaustive search, outperforms both the current practice of service selection and the previous algorithms for adaptive website design.\\n7. The performance of ServiceFinder is close to that of the optimal solution, indicating that the exhaustive search method is effective in finding the optimal solution.\\n```\\n\"]\n",
            "The rapid advancement of Internet technologies enables more and more educational institutes, companies, and government agencies to provide services, namely online services, through web portals. With hundreds of online services provided through a web portal, it is critical to design web portals, namely service portals, through which online services can be easily accessed by their consumers. This article addresses this critical issue from the perspective of service selection, that is, how to select a small number of service-links (i.e., hyperlinks pointing to online services) to be featured in the homepage of a service portal such that users can be directed to find the online services they seek most effectively. We propose a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services and formally define the service selection problem. A solution method, ServiceFinder, is then proposed. Using real-world data obtained from the Utah State Government service portal, we show that ServiceFinder outperforms both the current practice of service selection and previous algorithms for adaptive website design. We also show that the performance of ServiceFinder is close to that of the optimal solution resulting from exhaustive search.\n",
            "\n",
            "1.8 ['The', 'rapid', 'advancement', 'of', 'Internet', 'technologies', 'enables', 'more', 'and', 'more', 'educational', 'institutes,', 'companies,', 'and', 'government', 'agencies', 'to', 'provide', 'services,', 'namely', 'online', 'services,', 'through', 'web', 'portals.']\n",
            "0.7741935483870968 ['With', 'hundreds', 'of', 'online', 'services', 'provided', 'through', 'a', 'web', 'portal,', 'it', 'is', 'critical', 'to', 'design', 'web', 'portals,', 'namely', 'service', 'portals,', 'through', 'which', 'online', 'services', 'can', 'be', 'easily', 'accessed', 'by', 'their', 'consumers.']\n",
            "0.8695652173913043 ['This', 'article', 'addresses', 'this', 'critical', 'issue', 'from', 'the', 'perspective', 'of', 'service', 'selection,', 'that', 'is,', 'how', 'to', 'select', 'a', 'small', 'number', 'of', 'service-links', '(i.e.,']\n",
            "2.0 ['hyperlinks']\n",
            "1.4516129032258065 ['pointing', 'to', 'online', 'services)', 'to', 'be', 'featured', 'in', 'the', 'homepage', 'of', 'a', 'service', 'portal', 'such', 'that', 'users', 'can', 'be', 'directed', 'to', 'find', 'the', 'online', 'services', 'they', 'seek', 'most', 'effectively.', 'We', 'propose']\n",
            "1.5666666666666667 ['a', 'mathematically', 'formulated', 'metric', 'to', 'measure', 'the', 'effectiveness', 'of', 'the', 'selected', 'service-links', 'in', 'directing', 'users', 'to', 'locate', 'their', 'desired', 'online', 'services', 'and', 'formally', 'define', 'the', 'service', 'selection', 'problem.', 'A', 'solution']\n",
            "0.7142857142857143 ['method,', 'ServiceFinder,', 'is', 'then', 'proposed.', 'Using', 'real-world']\n",
            "1.0 ['data', 'obtained', 'from', 'the', 'Utah', 'State', 'Government', 'service', 'portal,', 'we', 'show', 'that', 'ServiceFinder', 'outperforms', 'both', 'the', 'current', 'practice', 'of', 'service', 'selection', 'and', 'previous', 'algorithms', 'for', 'adaptive', 'website', 'design.', 'We', 'also']\n",
            "1.35 ['show', 'that', 'the', 'performance', 'of', 'ServiceFinder', 'is', 'close', 'to', 'that', 'of', 'the', 'optimal', 'solution', 'resulting', 'from', 'exhaustive', 'search.']\n",
            "\n",
            "Kept segments where average matches > 1.28:\n",
            "Test case 5: 0.455172\n",
            "input = Stemmers attempt to reduce a word to its stem or root form and are used widely in information retrieval tasks to increase the recall rate. Most popular stemmers encode a large number of language-specific rules built over a length of time. Such stemmers with comprehensive rules are available only for a few languages. In the absence of extensive linguistic resources for certain languages, statistical language processing tools have been successfully used to improve the performance of IR systems. In this article, we describe a clustering-based approach to discover equivalence classes of root words and their morphological variants. A set of string distance measures are defined, and the lexicon for a given text collection is clustered using the distance measures to identify these equivalence classes. The proposed approach is compared with Porter's and Lovin's stemmers on the AP and WSJ subcollections of the Tipster dataset using 200 queries. Its performance is comparable to that of Porter's and Lovin's stemmers, both in terms of average precision and the total number of relevant documents retrieved. The proposed stemming algorithm also provides consistent improvements in retrieval performance for French and Bengali, which are currently resource-poor.\n",
            "\n",
            "ref = A set of string distance measures are defined, and the lexicon for a given text collection is clustered using the distance measures to identify these equivalence classes. The proposed approach is compared with Porter's and Lovin's stemmers on the AP and WSJ subcollections of the Tipster dataset using 200 queries.\n",
            "\n",
            "===============0====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```Stemmers attempt to reduce a word to its stem or root form and are used widely in information retrieval tasks to increase the recall rate. Most popular stemmers encode a large number of language-specific rules built over a length of time. Such stemmers with comprehensive rules are available only for a few languages. In the absence of extensive linguistic resources for certain languages, statistical language processing tools have been successfully used to improve the performance of IR systems. In this article, we describe a clustering-based approach to discover equivalence classes of root words and their morphological variants. A set of string distance measures are defined, and the lexicon for a given text collection is clustered using the distance measures to identify these equivalence classes. The proposed approach is compared with Porter's and Lovin's stemmers on the AP and WSJ subcollections of the Tipster dataset using 200 queries. Its performance is comparable to that of Porter's and Lovin's stemmers, both in terms of average precision and the total number of relevant documents retrieved. The proposed stemming algorithm also provides consistent improvements in retrieval performance for French and Bengali, which are currently resource-poor.\n",
            "``` Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================finish=================\n",
            "===============1====================\n",
            "From the following abstract, extract the sentences that shows the methods of the research. Only the sentences from the abstract, no other information.\n",
            "\n",
            "\n",
            "```Stemmers attempt to reduce a word to its stem or root form and are used widely in information retrieval tasks to increase the recall rate. Most popular stemmers encode a large number of language-specific rules built over a length of time. Such stemmers with comprehensive rules are available only for a few languages. In the absence of extensive linguistic resources for certain languages, statistical language processing tools have been successfully used to improve the performance of IR systems. In this article, we describe a clustering-based approach to discover equivalence classes of root words and their morphological variants. A set of string distance measures are defined, and the lexicon for a given text collection is clustered using the distance measures to identify these equivalence classes. The proposed approach is compared with Porter's and Lovin's stemmers on the AP and WSJ subcollections of the Tipster dataset using 200 queries. Its performance is comparable to that of Porter's and Lovin's stemmers, both in terms of average precision and the total number of relevant documents retrieved. The proposed stemming algorithm also provides consistent improvements in retrieval performance for French and Bengali, which are currently resource-poor.\n",
            "``` \n",
            " Don't predict line breaks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:inference device is not set, using cuda:0, Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y7Xm3hTcMGKU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}